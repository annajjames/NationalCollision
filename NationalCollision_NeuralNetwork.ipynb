{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b24c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.stats import reciprocal\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d497c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaefed58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_VEHS</th>\n",
       "      <th>C_CONF1</th>\n",
       "      <th>C_RCFG1</th>\n",
       "      <th>C_WTHR</th>\n",
       "      <th>C_RSUR</th>\n",
       "      <th>C_RALN</th>\n",
       "      <th>C_TRAF</th>\n",
       "      <th>V_TYPE1</th>\n",
       "      <th>P_SEX</th>\n",
       "      <th>P_AGE_CAT</th>\n",
       "      <th>P_PSN1</th>\n",
       "      <th>P_ISEV</th>\n",
       "      <th>P_SAFE1</th>\n",
       "      <th>P_USER1</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>time_sin</th>\n",
       "      <th>time_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>6</td>\n",
       "      <td>QQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.136167</td>\n",
       "      <td>-0.990686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.136167</td>\n",
       "      <td>-0.990686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-0.942261</td>\n",
       "      <td>-0.334880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-0.942261</td>\n",
       "      <td>-0.334880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>-0.942261</td>\n",
       "      <td>-0.334880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_VEHS C_CONF1 C_RCFG1 C_WTHR C_RSUR C_RALN C_TRAF V_TYPE1 P_SEX  \\\n",
       "0       2      32       1      1      5      4     18       1     M   \n",
       "1       2      32       1      1      5      4     18       1     F   \n",
       "2       2      32       1      2      5      3     18       1     F   \n",
       "3       2      32       1      2      5      3     18       1     F   \n",
       "4       2      32       1      2      5      3     18       1     M   \n",
       "\n",
       "   P_AGE_CAT P_PSN1  P_ISEV P_SAFE1  P_USER1  month_sin  month_cos   day_sin  \\\n",
       "0          6     QQ       1       2        2        0.5   0.866025  0.781831   \n",
       "1          3     11       0       2        1        0.5   0.866025  0.781831   \n",
       "2          3     11       0       2        1        0.5   0.866025  0.781831   \n",
       "3          1     33       1       2        2        0.5   0.866025  0.781831   \n",
       "4          2     11       0       2        1        0.5   0.866025  0.781831   \n",
       "\n",
       "   day_cos  time_sin  time_cos  \n",
       "0  0.62349  0.136167 -0.990686  \n",
       "1  0.62349  0.136167 -0.990686  \n",
       "2  0.62349 -0.942261 -0.334880  \n",
       "3  0.62349 -0.942261 -0.334880  \n",
       "4  0.62349 -0.942261 -0.334880  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"DataforML.csv\", low_memory='False', sep=',')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea075a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['P_AGE_CAT'] = df['P_AGE_CAT'].astype('category')\n",
    "df['P_USER1'] = df['P_USER1'].astype('object')\n",
    "df['P_USER1'] = df['P_USER1'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29246199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 237870 entries, 0 to 237869\n",
      "Data columns (total 20 columns):\n",
      " #   Column     Non-Null Count   Dtype   \n",
      "---  ------     --------------   -----   \n",
      " 0   C_VEHS     237870 non-null  int64   \n",
      " 1   C_CONF1    237870 non-null  object  \n",
      " 2   C_RCFG1    237870 non-null  object  \n",
      " 3   C_WTHR     237870 non-null  object  \n",
      " 4   C_RSUR     237870 non-null  object  \n",
      " 5   C_RALN     237870 non-null  object  \n",
      " 6   C_TRAF     237870 non-null  object  \n",
      " 7   V_TYPE1    237870 non-null  object  \n",
      " 8   P_SEX      237870 non-null  object  \n",
      " 9   P_AGE_CAT  237870 non-null  category\n",
      " 10  P_PSN1     237870 non-null  object  \n",
      " 11  P_ISEV     237870 non-null  int64   \n",
      " 12  P_SAFE1    237870 non-null  object  \n",
      " 13  P_USER1    237870 non-null  object  \n",
      " 14  month_sin  237870 non-null  float64 \n",
      " 15  month_cos  237870 non-null  float64 \n",
      " 16  day_sin    237870 non-null  float64 \n",
      " 17  day_cos    237870 non-null  float64 \n",
      " 18  time_sin   237870 non-null  float64 \n",
      " 19  time_cos   237870 non-null  float64 \n",
      "dtypes: category(1), float64(6), int64(2), object(11)\n",
      "memory usage: 34.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7db78e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "Target = 'P_ISEV'\n",
    "columns_pred = [col for col in df.columns if col not in [Target]]\n",
    "columns_num = list(df.select_dtypes(include=[np.number]).drop(Target, axis=1).columns)\n",
    "columns_cat = list(df.select_dtypes(exclude=[np.number]).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a066a1f8",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d59ed30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((237870, 19), (237870,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[columns_pred]\n",
    "y = df[Target]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cb84b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (166509, 19)\n",
      "X test shape:  (71361, 19)\n",
      "y train shape:  (166509,)\n",
      "y test shape:  (71361,)\n"
     ]
    }
   ],
   "source": [
    "#Stratify split data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "print(\"X train shape: \", X_train.shape)\n",
    "print(\"X test shape: \", X_test.shape)\n",
    "print(\"y train shape: \", y_train.shape)\n",
    "print(\"y test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef11cea",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "606cd2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline for categorical features\n",
    "\n",
    "pipe_cat = Pipeline([('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "                    ('select', SelectKBest(score_func=chi2, k=35)),\n",
    "                    ])\n",
    "\n",
    "#Pipeline for numerical features\n",
    "\n",
    "pipe_num = Pipeline([('scaler', StandardScaler()),\n",
    "                    ])\n",
    "\n",
    "#Pre-processing pipeline to combine both categorical and numerical features\n",
    "\n",
    "pipe_preprocessor = ColumnTransformer([('categorical', pipe_cat, columns_cat),\n",
    "                                      ('numerical', pipe_num, columns_num),\n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf3b9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform both train and test data\n",
    "\n",
    "X_train_transformed = pipe_preprocessor.fit(X_train, y_train).transform(X_train) #SelectKBest uses fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a8e62e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = pipe_preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "092d6119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((166509, 42), (71361, 42))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape, X_test_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7a5f38",
   "metadata": {},
   "source": [
    "### Sequential model with BatchNormalization, selu activation and Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1d5a73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2998/2998 [==============================] - 5s 1ms/step - loss: 0.6287 - accuracy: 0.6346 - val_loss: 0.5971 - val_accuracy: 0.6670\n",
      "Epoch 2/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.6039 - accuracy: 0.6560 - val_loss: 0.5893 - val_accuracy: 0.6658\n",
      "Epoch 3/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5997 - accuracy: 0.6614 - val_loss: 0.5909 - val_accuracy: 0.6663\n",
      "Epoch 4/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5963 - accuracy: 0.6630 - val_loss: 0.5891 - val_accuracy: 0.6690\n",
      "Epoch 5/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5936 - accuracy: 0.6656 - val_loss: 0.5883 - val_accuracy: 0.6722\n",
      "Epoch 6/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5954 - accuracy: 0.6637 - val_loss: 0.5866 - val_accuracy: 0.6735\n",
      "Epoch 7/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5927 - accuracy: 0.6660 - val_loss: 0.5877 - val_accuracy: 0.6677\n",
      "Epoch 8/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5924 - accuracy: 0.6663 - val_loss: 0.5910 - val_accuracy: 0.6660\n",
      "Epoch 9/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5907 - accuracy: 0.6685 - val_loss: 0.5861 - val_accuracy: 0.6735\n",
      "Epoch 10/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5926 - accuracy: 0.6658 - val_loss: 0.5863 - val_accuracy: 0.6696\n",
      "Epoch 11/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5910 - accuracy: 0.6663 - val_loss: 0.5847 - val_accuracy: 0.6715\n",
      "Epoch 12/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5907 - accuracy: 0.6656 - val_loss: 0.5847 - val_accuracy: 0.6738\n",
      "Epoch 13/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5909 - accuracy: 0.6649 - val_loss: 0.5851 - val_accuracy: 0.6720\n",
      "Epoch 14/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5890 - accuracy: 0.6694 - val_loss: 0.5865 - val_accuracy: 0.6745\n",
      "Epoch 15/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5879 - accuracy: 0.6682 - val_loss: 0.5853 - val_accuracy: 0.6731\n",
      "Epoch 16/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5907 - accuracy: 0.6664 - val_loss: 0.5842 - val_accuracy: 0.6701\n",
      "Epoch 17/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5879 - accuracy: 0.6691 - val_loss: 0.5847 - val_accuracy: 0.6741\n",
      "Epoch 18/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5890 - accuracy: 0.6687 - val_loss: 0.5834 - val_accuracy: 0.6730\n",
      "Epoch 19/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5879 - accuracy: 0.6699 - val_loss: 0.5826 - val_accuracy: 0.6746\n",
      "Epoch 20/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5869 - accuracy: 0.6702 - val_loss: 0.5820 - val_accuracy: 0.6749\n",
      "Epoch 21/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5882 - accuracy: 0.6691 - val_loss: 0.5834 - val_accuracy: 0.6728\n",
      "Epoch 22/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5901 - accuracy: 0.6678 - val_loss: 0.5835 - val_accuracy: 0.6745\n",
      "Epoch 23/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5871 - accuracy: 0.6717 - val_loss: 0.5832 - val_accuracy: 0.6752\n",
      "Epoch 24/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5866 - accuracy: 0.6710 - val_loss: 0.5825 - val_accuracy: 0.6747\n",
      "Epoch 25/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5860 - accuracy: 0.6724 - val_loss: 0.5833 - val_accuracy: 0.6743\n",
      "Epoch 26/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5859 - accuracy: 0.6711 - val_loss: 0.5847 - val_accuracy: 0.6714\n",
      "Epoch 27/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5876 - accuracy: 0.6703 - val_loss: 0.5859 - val_accuracy: 0.6718\n",
      "Epoch 28/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5868 - accuracy: 0.6691 - val_loss: 0.5851 - val_accuracy: 0.6712\n",
      "Epoch 29/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5858 - accuracy: 0.6701 - val_loss: 0.5824 - val_accuracy: 0.6734\n",
      "Epoch 30/100\n",
      "2998/2998 [==============================] - 4s 1ms/step - loss: 0.5847 - accuracy: 0.6712 - val_loss: 0.5846 - val_accuracy: 0.6703\n"
     ]
    }
   ],
   "source": [
    "model1 = keras.models.Sequential()\n",
    "model1.add(keras.layers.Flatten(input_shape=X_train_transformed.shape[1:]))\n",
    "for i in range(10):\n",
    "    model1.add(keras.layers.Dense(30, kernel_initializer='lecun_normal'))\n",
    "    model1.add(keras.layers.BatchNormalization())\n",
    "    model1.add(keras.layers.Activation(activation='selu'))\n",
    "model1.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model1.compile(loss=keras.losses.binary_crossentropy, \n",
    "              optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "#checkpoint_cb = keras.callbacks.ModelCheckpoint('model_he_adam.h5', save_best_only=True)\n",
    "\n",
    "hist1 = model1.fit(X_train_transformed, y_train, epochs=100, batch_size=50, validation_split=0.1,\n",
    "          callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c6e236b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2231/2231 [==============================] - 1s 361us/step - loss: 0.5886 - accuracy: 0.6674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5886420607566833, 0.6673813462257385]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test_transformed, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee91df27",
   "metadata": {},
   "source": [
    "batchsize change with elu, 20 layers, 28 neurons \n",
    "batch size = 50 accuracy on test = 66.9, \n",
    "100 accuracy on test = 66.69\n",
    "\n",
    "selu (super fast) - 10 layers, 30 nodes, batch size=50, adam, accuracy = 67, test - 66.7\n",
    "20 layers accuracy = almost same as above. keep 10 layers\n",
    "\n",
    "PReLU - 10 layers, 30 neuron, batch=50, accuracy= 67, test - 66.7\n",
    "20 layers, 30 neurons, batch=50 acc = 66.6, test - 66.6\n",
    "\n",
    "keep selu, with BN - \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f1228e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist1.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(hist1.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.gca().set_xlim(0,25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "853ecf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the best model saved\n",
    "\n",
    "model_he_adam = keras.models.load_model('model_he_adam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba70f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_he_adam.get_config()['layers'][2]['config']['kernel_initializer']['class_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f355e7",
   "metadata": {},
   "source": [
    "## Tuning neural network hyperparameters:\n",
    "### GridSearchCV using Keras.wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f226195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funtion to create a simple network with Batch Normalization to search for number of layers, number of nodes and\n",
    "#batch size with selu activation and Adam optimizer default learning_rate 0.001 and early stopping\n",
    "\n",
    "\n",
    "def build_model_bn(n_hidden=10, n_neurons=30):\n",
    "    model_bn = keras.models.Sequential()\n",
    "    model_bn.add(keras.layers.InputLayer(input_shape=X_train_transformed.shape[1:]))\n",
    "    for layer in range(n_hidden):\n",
    "        model_bn.add(keras.layers.Dense(n_neurons, kernel_initializer='lecun_normal'))\n",
    "        model_bn.add(keras.layers.BatchNormalization())\n",
    "        model_bn.add(keras.layers.Activation(activation='selu'))\n",
    "    model_bn.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model_bn.compile(loss=keras.losses.binary_crossentropy, \n",
    "              optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999), \n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "661bd3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crate a wrapper to use in GridSearchCV\n",
    "\n",
    "keras_classif = keras.wrappers.scikit_learn.KerasClassifier(build_model_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "229d070c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 4s 693us/step - loss: 0.6327 - accuracy: 0.6294 - val_loss: 0.5994 - val_accuracy: 0.6644\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 3s 672us/step - loss: 0.6068 - accuracy: 0.6565 - val_loss: 0.5943 - val_accuracy: 0.6673\n",
      "Epoch 3/100\n",
      "4996/4996 [==============================] - 3s 679us/step - loss: 0.6035 - accuracy: 0.6576 - val_loss: 0.5915 - val_accuracy: 0.6688\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 3s 673us/step - loss: 0.5994 - accuracy: 0.6589 - val_loss: 0.5890 - val_accuracy: 0.6685\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 3s 670us/step - loss: 0.5993 - accuracy: 0.6561 - val_loss: 0.5880 - val_accuracy: 0.6720\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 3s 674us/step - loss: 0.5967 - accuracy: 0.6612 - val_loss: 0.5900 - val_accuracy: 0.6736\n",
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 3s 666us/step - loss: 0.5977 - accuracy: 0.6593 - val_loss: 0.5898 - val_accuracy: 0.6712\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 3s 667us/step - loss: 0.5941 - accuracy: 0.6639 - val_loss: 0.5856 - val_accuracy: 0.6721\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 3s 670us/step - loss: 0.5947 - accuracy: 0.6611 - val_loss: 0.5873 - val_accuracy: 0.6726\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 3s 680us/step - loss: 0.5960 - accuracy: 0.6612 - val_loss: 0.5914 - val_accuracy: 0.6716\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 3s 674us/step - loss: 0.5929 - accuracy: 0.6658 - val_loss: 0.5877 - val_accuracy: 0.6715\n",
      "Epoch 12/100\n",
      "4996/4996 [==============================] - 3s 673us/step - loss: 0.5957 - accuracy: 0.6622 - val_loss: 0.5889 - val_accuracy: 0.6708\n",
      "Epoch 13/100\n",
      "4996/4996 [==============================] - 3s 670us/step - loss: 0.5937 - accuracy: 0.6638 - val_loss: 0.5907 - val_accuracy: 0.6712\n",
      "2776/2776 [==============================] - 1s 252us/step - loss: 0.5912 - accuracy: 0.6684\n",
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 4s 685us/step - loss: 0.6258 - accuracy: 0.6347 - val_loss: 0.6039 - val_accuracy: 0.6585\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 3s 669us/step - loss: 0.6109 - accuracy: 0.6505 - val_loss: 0.5935 - val_accuracy: 0.6659\n",
      "Epoch 3/100\n",
      "4996/4996 [==============================] - 3s 670us/step - loss: 0.6035 - accuracy: 0.6566 - val_loss: 0.5891 - val_accuracy: 0.6712\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 3s 666us/step - loss: 0.6027 - accuracy: 0.6572 - val_loss: 0.5920 - val_accuracy: 0.6651\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 3s 665us/step - loss: 0.5978 - accuracy: 0.6611 - val_loss: 0.5903 - val_accuracy: 0.6691\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 3s 665us/step - loss: 0.5991 - accuracy: 0.6603 - val_loss: 0.5866 - val_accuracy: 0.6710\n",
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 3s 671us/step - loss: 0.5975 - accuracy: 0.6602 - val_loss: 0.5912 - val_accuracy: 0.6703\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 3s 668us/step - loss: 0.5951 - accuracy: 0.6619 - val_loss: 0.5893 - val_accuracy: 0.6719\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 3s 666us/step - loss: 0.5971 - accuracy: 0.6612 - val_loss: 0.5929 - val_accuracy: 0.6701\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 3s 670us/step - loss: 0.5959 - accuracy: 0.6632 - val_loss: 0.5872 - val_accuracy: 0.6711\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 3s 665us/step - loss: 0.5946 - accuracy: 0.6643 - val_loss: 0.5853 - val_accuracy: 0.6719\n",
      "Epoch 12/100\n",
      "4996/4996 [==============================] - 3s 671us/step - loss: 0.5957 - accuracy: 0.6630 - val_loss: 0.5859 - val_accuracy: 0.6731\n",
      "Epoch 13/100\n",
      "4996/4996 [==============================] - 3s 682us/step - loss: 0.5956 - accuracy: 0.6626 - val_loss: 0.5856 - val_accuracy: 0.6725\n",
      "Epoch 14/100\n",
      "4996/4996 [==============================] - 3s 681us/step - loss: 0.5933 - accuracy: 0.6647 - val_loss: 0.5872 - val_accuracy: 0.6730\n",
      "Epoch 15/100\n",
      "4996/4996 [==============================] - 3s 686us/step - loss: 0.5934 - accuracy: 0.6646 - val_loss: 0.5843 - val_accuracy: 0.6737\n",
      "Epoch 16/100\n",
      "4996/4996 [==============================] - 3s 672us/step - loss: 0.5935 - accuracy: 0.6639 - val_loss: 0.5877 - val_accuracy: 0.6719\n",
      "Epoch 17/100\n",
      "4996/4996 [==============================] - 3s 677us/step - loss: 0.5922 - accuracy: 0.6681 - val_loss: 0.5871 - val_accuracy: 0.6728\n",
      "Epoch 18/100\n",
      "4996/4996 [==============================] - 3s 679us/step - loss: 0.5939 - accuracy: 0.6626 - val_loss: 0.5861 - val_accuracy: 0.6750\n",
      "Epoch 19/100\n",
      "4996/4996 [==============================] - 3s 675us/step - loss: 0.5905 - accuracy: 0.6674 - val_loss: 0.5833 - val_accuracy: 0.6736\n",
      "Epoch 20/100\n",
      "4996/4996 [==============================] - 3s 686us/step - loss: 0.5897 - accuracy: 0.6677 - val_loss: 0.5878 - val_accuracy: 0.6717\n",
      "Epoch 21/100\n",
      "4996/4996 [==============================] - 3s 672us/step - loss: 0.5936 - accuracy: 0.6653 - val_loss: 0.5844 - val_accuracy: 0.6734\n",
      "Epoch 22/100\n",
      "4996/4996 [==============================] - 3s 678us/step - loss: 0.5915 - accuracy: 0.6664 - val_loss: 0.5922 - val_accuracy: 0.6662\n",
      "Epoch 23/100\n",
      "4996/4996 [==============================] - 4s 711us/step - loss: 0.5919 - accuracy: 0.6654 - val_loss: 0.5871 - val_accuracy: 0.6733\n",
      "Epoch 24/100\n",
      "4996/4996 [==============================] - 3s 677us/step - loss: 0.5925 - accuracy: 0.6631 - val_loss: 0.5860 - val_accuracy: 0.6727\n",
      "2776/2776 [==============================] - 1s 246us/step - loss: 0.5891 - accuracy: 0.6677\n",
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 4s 675us/step - loss: 0.6327 - accuracy: 0.6316 - val_loss: 0.6123 - val_accuracy: 0.6551\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 3s 661us/step - loss: 0.6094 - accuracy: 0.6502 - val_loss: 0.6045 - val_accuracy: 0.6608\n",
      "Epoch 3/100\n",
      "4996/4996 [==============================] - 3s 654us/step - loss: 0.6063 - accuracy: 0.6527 - val_loss: 0.6034 - val_accuracy: 0.6614\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 3s 652us/step - loss: 0.6028 - accuracy: 0.6557 - val_loss: 0.6006 - val_accuracy: 0.6566\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 3s 658us/step - loss: 0.6020 - accuracy: 0.6551 - val_loss: 0.5964 - val_accuracy: 0.6638\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 3s 656us/step - loss: 0.5992 - accuracy: 0.6590 - val_loss: 0.5981 - val_accuracy: 0.6595\n",
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 3s 653us/step - loss: 0.5977 - accuracy: 0.6604 - val_loss: 0.5988 - val_accuracy: 0.6606\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 3s 654us/step - loss: 0.5961 - accuracy: 0.6622 - val_loss: 0.5970 - val_accuracy: 0.6613\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 3s 653us/step - loss: 0.5943 - accuracy: 0.6631 - val_loss: 0.5982 - val_accuracy: 0.6557\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 3s 653us/step - loss: 0.5963 - accuracy: 0.6611 - val_loss: 0.5959 - val_accuracy: 0.6630\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 3s 657us/step - loss: 0.5933 - accuracy: 0.6663 - val_loss: 0.5936 - val_accuracy: 0.6641\n",
      "Epoch 12/100\n",
      "4996/4996 [==============================] - 3s 653us/step - loss: 0.5961 - accuracy: 0.6633 - val_loss: 0.5961 - val_accuracy: 0.6635\n",
      "Epoch 13/100\n",
      "4996/4996 [==============================] - 3s 653us/step - loss: 0.5944 - accuracy: 0.6636 - val_loss: 0.6003 - val_accuracy: 0.6597\n",
      "Epoch 14/100\n",
      "4996/4996 [==============================] - 3s 651us/step - loss: 0.5916 - accuracy: 0.6674 - val_loss: 0.5943 - val_accuracy: 0.6626\n",
      "Epoch 15/100\n",
      "4996/4996 [==============================] - 3s 657us/step - loss: 0.5953 - accuracy: 0.6621 - val_loss: 0.5959 - val_accuracy: 0.6613\n",
      "Epoch 16/100\n",
      "4996/4996 [==============================] - 3s 654us/step - loss: 0.5912 - accuracy: 0.6652 - val_loss: 0.5988 - val_accuracy: 0.6626\n",
      "2776/2776 [==============================] - 1s 245us/step - loss: 0.5891 - accuracy: 0.6697\n",
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 4s 725us/step - loss: 0.6312 - accuracy: 0.6276 - val_loss: 0.6002 - val_accuracy: 0.6644\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 4s 704us/step - loss: 0.6102 - accuracy: 0.6496 - val_loss: 0.5978 - val_accuracy: 0.6645\n",
      "Epoch 3/100\n",
      "4996/4996 [==============================] - 4s 703us/step - loss: 0.6044 - accuracy: 0.6557 - val_loss: 0.5942 - val_accuracy: 0.6673\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 4s 707us/step - loss: 0.6026 - accuracy: 0.6581 - val_loss: 0.5898 - val_accuracy: 0.6672\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 4s 706us/step - loss: 0.6011 - accuracy: 0.6571 - val_loss: 0.5889 - val_accuracy: 0.6712\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 4s 705us/step - loss: 0.5979 - accuracy: 0.6628 - val_loss: 0.5886 - val_accuracy: 0.6701\n",
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 4s 703us/step - loss: 0.5991 - accuracy: 0.6581 - val_loss: 0.5884 - val_accuracy: 0.6677\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 4s 703us/step - loss: 0.5950 - accuracy: 0.6642 - val_loss: 0.5948 - val_accuracy: 0.6666\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 4s 707us/step - loss: 0.5962 - accuracy: 0.6602 - val_loss: 0.5925 - val_accuracy: 0.6705\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 4s 707us/step - loss: 0.5951 - accuracy: 0.6624 - val_loss: 0.5869 - val_accuracy: 0.6693\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 4s 708us/step - loss: 0.5937 - accuracy: 0.6642 - val_loss: 0.5909 - val_accuracy: 0.6711\n",
      "Epoch 12/100\n",
      "4996/4996 [==============================] - 4s 707us/step - loss: 0.5934 - accuracy: 0.6654 - val_loss: 0.5905 - val_accuracy: 0.6706\n",
      "Epoch 13/100\n",
      "4996/4996 [==============================] - 4s 703us/step - loss: 0.5897 - accuracy: 0.6688 - val_loss: 0.5874 - val_accuracy: 0.6732\n",
      "Epoch 14/100\n",
      "4996/4996 [==============================] - 4s 717us/step - loss: 0.5920 - accuracy: 0.6669 - val_loss: 0.5860 - val_accuracy: 0.6768\n",
      "Epoch 15/100\n",
      "4996/4996 [==============================] - 3s 695us/step - loss: 0.5909 - accuracy: 0.6674 - val_loss: 0.5912 - val_accuracy: 0.6687\n",
      "Epoch 16/100\n",
      "4996/4996 [==============================] - 3s 697us/step - loss: 0.5923 - accuracy: 0.6652 - val_loss: 0.5888 - val_accuracy: 0.6720\n",
      "Epoch 17/100\n",
      "4996/4996 [==============================] - 3s 698us/step - loss: 0.5921 - accuracy: 0.6657 - val_loss: 0.5935 - val_accuracy: 0.6580\n",
      "Epoch 18/100\n",
      "4996/4996 [==============================] - 3s 700us/step - loss: 0.5911 - accuracy: 0.6671 - val_loss: 0.5888 - val_accuracy: 0.6742\n",
      "Epoch 19/100\n",
      "4996/4996 [==============================] - 3s 698us/step - loss: 0.5912 - accuracy: 0.6653 - val_loss: 0.5894 - val_accuracy: 0.6710\n",
      "2776/2776 [==============================] - 1s 256us/step - loss: 0.5921 - accuracy: 0.6682\n",
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 4s 718us/step - loss: 0.6339 - accuracy: 0.6288 - val_loss: 0.5990 - val_accuracy: 0.6619\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 4s 701us/step - loss: 0.6076 - accuracy: 0.6542 - val_loss: 0.5927 - val_accuracy: 0.6675\n",
      "Epoch 3/100\n",
      "4996/4996 [==============================] - 4s 701us/step - loss: 0.6036 - accuracy: 0.6564 - val_loss: 0.5906 - val_accuracy: 0.6671\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 4s 701us/step - loss: 0.6008 - accuracy: 0.6573 - val_loss: 0.5872 - val_accuracy: 0.6661\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 4s 702us/step - loss: 0.5980 - accuracy: 0.6623 - val_loss: 0.5905 - val_accuracy: 0.6706\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 4s 718us/step - loss: 0.6003 - accuracy: 0.6587 - val_loss: 0.5862 - val_accuracy: 0.6723\n",
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 3s 698us/step - loss: 0.5985 - accuracy: 0.6613 - val_loss: 0.5902 - val_accuracy: 0.6716\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 4s 705us/step - loss: 0.5960 - accuracy: 0.6643 - val_loss: 0.5902 - val_accuracy: 0.6711\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 3s 698us/step - loss: 0.5955 - accuracy: 0.6632 - val_loss: 0.5851 - val_accuracy: 0.6719\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 4s 702us/step - loss: 0.5924 - accuracy: 0.6648 - val_loss: 0.5862 - val_accuracy: 0.6733\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 4s 704us/step - loss: 0.5961 - accuracy: 0.6634 - val_loss: 0.5845 - val_accuracy: 0.6744\n",
      "Epoch 12/100\n",
      "4996/4996 [==============================] - 4s 701us/step - loss: 0.5938 - accuracy: 0.6645 - val_loss: 0.5855 - val_accuracy: 0.6728\n",
      "Epoch 13/100\n",
      "4996/4996 [==============================] - 3s 700us/step - loss: 0.5933 - accuracy: 0.6648 - val_loss: 0.5854 - val_accuracy: 0.6735\n",
      "Epoch 14/100\n",
      "4996/4996 [==============================] - 3s 697us/step - loss: 0.5962 - accuracy: 0.6625 - val_loss: 0.5879 - val_accuracy: 0.6721\n",
      "Epoch 15/100\n",
      "4996/4996 [==============================] - 4s 705us/step - loss: 0.5920 - accuracy: 0.6659 - val_loss: 0.5877 - val_accuracy: 0.6721\n",
      "Epoch 16/100\n",
      "4996/4996 [==============================] - 4s 701us/step - loss: 0.5917 - accuracy: 0.6666 - val_loss: 0.5869 - val_accuracy: 0.6735\n",
      "2776/2776 [==============================] - 1s 250us/step - loss: 0.5899 - accuracy: 0.6663\n",
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 4s 779us/step - loss: 0.6327 - accuracy: 0.6302 - val_loss: 0.6041 - val_accuracy: 0.6571\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 4s 704us/step - loss: 0.6098 - accuracy: 0.6474 - val_loss: 0.6023 - val_accuracy: 0.6583\n",
      "Epoch 3/100\n",
      "4996/4996 [==============================] - 4s 707us/step - loss: 0.6057 - accuracy: 0.6551 - val_loss: 0.6007 - val_accuracy: 0.6575\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 4s 702us/step - loss: 0.6012 - accuracy: 0.6563 - val_loss: 0.6001 - val_accuracy: 0.6596\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 4s 706us/step - loss: 0.6005 - accuracy: 0.6583 - val_loss: 0.5967 - val_accuracy: 0.6599\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 4s 701us/step - loss: 0.5976 - accuracy: 0.6611 - val_loss: 0.5980 - val_accuracy: 0.6626\n",
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 4s 710us/step - loss: 0.5966 - accuracy: 0.6612 - val_loss: 0.5976 - val_accuracy: 0.6632\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 4s 703us/step - loss: 0.5968 - accuracy: 0.6603 - val_loss: 0.5959 - val_accuracy: 0.6637\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 4s 701us/step - loss: 0.5961 - accuracy: 0.6640 - val_loss: 0.5980 - val_accuracy: 0.6662\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 4s 702us/step - loss: 0.5952 - accuracy: 0.6646 - val_loss: 0.5983 - val_accuracy: 0.6618\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 4s 701us/step - loss: 0.5957 - accuracy: 0.6607 - val_loss: 0.5989 - val_accuracy: 0.6612\n",
      "Epoch 12/100\n",
      "4996/4996 [==============================] - 3s 698us/step - loss: 0.5969 - accuracy: 0.6603 - val_loss: 0.5986 - val_accuracy: 0.6621\n",
      "Epoch 13/100\n",
      "4996/4996 [==============================] - 4s 701us/step - loss: 0.5931 - accuracy: 0.6655 - val_loss: 0.5965 - val_accuracy: 0.6657\n",
      "2776/2776 [==============================] - 1s 253us/step - loss: 0.5919 - accuracy: 0.6688\n",
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6398 - accuracy: 0.6241 - val_loss: 0.6018 - val_accuracy: 0.6616\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.6149 - accuracy: 0.6462 - val_loss: 0.5987 - val_accuracy: 0.6654\n",
      "Epoch 3/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.6098 - accuracy: 0.6522 - val_loss: 0.5947 - val_accuracy: 0.6626\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.6054 - accuracy: 0.6550 - val_loss: 0.5997 - val_accuracy: 0.6622\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.6029 - accuracy: 0.6586 - val_loss: 0.5927 - val_accuracy: 0.6701\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5994 - accuracy: 0.6602 - val_loss: 0.5919 - val_accuracy: 0.6672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5986 - accuracy: 0.6630 - val_loss: 0.5909 - val_accuracy: 0.6689\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5980 - accuracy: 0.6603 - val_loss: 0.5922 - val_accuracy: 0.6714\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5964 - accuracy: 0.6640 - val_loss: 0.5902 - val_accuracy: 0.6710\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5972 - accuracy: 0.6638 - val_loss: 0.5910 - val_accuracy: 0.6662\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5969 - accuracy: 0.6590 - val_loss: 0.5909 - val_accuracy: 0.6726\n",
      "Epoch 12/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5953 - accuracy: 0.6645 - val_loss: 0.5878 - val_accuracy: 0.6736\n",
      "Epoch 13/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5953 - accuracy: 0.6648 - val_loss: 0.5870 - val_accuracy: 0.6722\n",
      "Epoch 14/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5945 - accuracy: 0.6659 - val_loss: 0.5914 - val_accuracy: 0.6705\n",
      "Epoch 15/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5939 - accuracy: 0.6642 - val_loss: 0.5931 - val_accuracy: 0.6745\n",
      "Epoch 16/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5923 - accuracy: 0.6679 - val_loss: 0.5897 - val_accuracy: 0.6611\n",
      "Epoch 17/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5932 - accuracy: 0.6652 - val_loss: 0.5869 - val_accuracy: 0.6716\n",
      "Epoch 18/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5917 - accuracy: 0.6656 - val_loss: 0.5913 - val_accuracy: 0.6739\n",
      "Epoch 19/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5917 - accuracy: 0.6665 - val_loss: 0.5881 - val_accuracy: 0.6682\n",
      "Epoch 20/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5927 - accuracy: 0.6640 - val_loss: 0.5880 - val_accuracy: 0.6736\n",
      "Epoch 21/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5914 - accuracy: 0.6678 - val_loss: 0.5875 - val_accuracy: 0.6735\n",
      "Epoch 22/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5947 - accuracy: 0.6637 - val_loss: 0.5886 - val_accuracy: 0.6725\n",
      "2776/2776 [==============================] - 1s 314us/step - loss: 0.5929 - accuracy: 0.6676\n",
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6395 - accuracy: 0.6234 - val_loss: 0.6050 - val_accuracy: 0.6613\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.6124 - accuracy: 0.6514 - val_loss: 0.5950 - val_accuracy: 0.6654\n",
      "Epoch 3/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.6071 - accuracy: 0.6556 - val_loss: 0.5940 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.6032 - accuracy: 0.6559 - val_loss: 0.5907 - val_accuracy: 0.6684\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.6016 - accuracy: 0.6596 - val_loss: 0.5900 - val_accuracy: 0.6687\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5984 - accuracy: 0.6626 - val_loss: 0.5929 - val_accuracy: 0.6711\n",
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5977 - accuracy: 0.6611 - val_loss: 0.5860 - val_accuracy: 0.6725\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5974 - accuracy: 0.6628 - val_loss: 0.5938 - val_accuracy: 0.6684\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5980 - accuracy: 0.6618 - val_loss: 0.5888 - val_accuracy: 0.6689\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5957 - accuracy: 0.6666 - val_loss: 0.5885 - val_accuracy: 0.6698\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5951 - accuracy: 0.6633 - val_loss: 0.5891 - val_accuracy: 0.6697\n",
      "Epoch 12/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5962 - accuracy: 0.6627 - val_loss: 0.5909 - val_accuracy: 0.6691\n",
      "2776/2776 [==============================] - 1s 309us/step - loss: 0.5909 - accuracy: 0.6666\n",
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6363 - accuracy: 0.6269 - val_loss: 0.6053 - val_accuracy: 0.6564\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.6116 - accuracy: 0.6487 - val_loss: 0.6068 - val_accuracy: 0.6571\n",
      "Epoch 3/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.6071 - accuracy: 0.6540 - val_loss: 0.6026 - val_accuracy: 0.6580\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.6057 - accuracy: 0.6550 - val_loss: 0.5981 - val_accuracy: 0.6603\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.6031 - accuracy: 0.6569 - val_loss: 0.6017 - val_accuracy: 0.6615\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.6021 - accuracy: 0.6555 - val_loss: 0.5974 - val_accuracy: 0.6645\n",
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.6009 - accuracy: 0.6568 - val_loss: 0.6006 - val_accuracy: 0.6589\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5975 - accuracy: 0.6622 - val_loss: 0.6021 - val_accuracy: 0.6592\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5988 - accuracy: 0.6593 - val_loss: 0.5978 - val_accuracy: 0.6642\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5988 - accuracy: 0.6616 - val_loss: 0.5956 - val_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5968 - accuracy: 0.6620 - val_loss: 0.5954 - val_accuracy: 0.6653\n",
      "Epoch 12/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5946 - accuracy: 0.6662 - val_loss: 0.5958 - val_accuracy: 0.6631\n",
      "Epoch 13/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5964 - accuracy: 0.6618 - val_loss: 0.5994 - val_accuracy: 0.6633\n",
      "Epoch 14/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5950 - accuracy: 0.6652 - val_loss: 0.5946 - val_accuracy: 0.6636\n",
      "Epoch 15/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5941 - accuracy: 0.6654 - val_loss: 0.5975 - val_accuracy: 0.6651\n",
      "Epoch 16/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5914 - accuracy: 0.6679 - val_loss: 0.6027 - val_accuracy: 0.6524\n",
      "Epoch 17/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5941 - accuracy: 0.6646 - val_loss: 0.5977 - val_accuracy: 0.6610\n",
      "Epoch 18/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5926 - accuracy: 0.6649 - val_loss: 0.5969 - val_accuracy: 0.6605\n",
      "Epoch 19/100\n",
      "4996/4996 [==============================] - 5s 1ms/step - loss: 0.5933 - accuracy: 0.6663 - val_loss: 0.5973 - val_accuracy: 0.6619\n",
      "2776/2776 [==============================] - 1s 310us/step - loss: 0.5893 - accuracy: 0.6698\n",
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6383 - accuracy: 0.6179 - val_loss: 0.5980 - val_accuracy: 0.6654\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6100 - accuracy: 0.6498 - val_loss: 0.5954 - val_accuracy: 0.6686\n",
      "Epoch 3/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6080 - accuracy: 0.6533 - val_loss: 0.5933 - val_accuracy: 0.6676\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6049 - accuracy: 0.6538 - val_loss: 0.5935 - val_accuracy: 0.6671\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6019 - accuracy: 0.6535 - val_loss: 0.5983 - val_accuracy: 0.6663\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6015 - accuracy: 0.6559 - val_loss: 0.5897 - val_accuracy: 0.6680\n",
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6018 - accuracy: 0.6550 - val_loss: 0.5938 - val_accuracy: 0.6704\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5984 - accuracy: 0.6594 - val_loss: 0.5879 - val_accuracy: 0.6720\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5986 - accuracy: 0.6614 - val_loss: 0.5966 - val_accuracy: 0.6615\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5943 - accuracy: 0.6650 - val_loss: 0.5903 - val_accuracy: 0.6683\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5967 - accuracy: 0.6629 - val_loss: 0.5855 - val_accuracy: 0.6722\n",
      "Epoch 12/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5945 - accuracy: 0.6636 - val_loss: 0.5891 - val_accuracy: 0.6698\n",
      "Epoch 13/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5957 - accuracy: 0.6649 - val_loss: 0.5916 - val_accuracy: 0.6677\n",
      "Epoch 14/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5945 - accuracy: 0.6640 - val_loss: 0.5873 - val_accuracy: 0.6622\n",
      "Epoch 15/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5952 - accuracy: 0.6606 - val_loss: 0.5984 - val_accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5932 - accuracy: 0.6623 - val_loss: 0.5920 - val_accuracy: 0.6632\n",
      "2776/2776 [==============================] - 1s 330us/step - loss: 0.5917 - accuracy: 0.6676\n",
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6350 - accuracy: 0.6290 - val_loss: 0.5999 - val_accuracy: 0.6634\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6125 - accuracy: 0.6518 - val_loss: 0.5994 - val_accuracy: 0.6656\n",
      "Epoch 3/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6107 - accuracy: 0.6532 - val_loss: 0.5962 - val_accuracy: 0.6669\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6063 - accuracy: 0.6568 - val_loss: 0.5944 - val_accuracy: 0.6662\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6034 - accuracy: 0.6582 - val_loss: 0.5908 - val_accuracy: 0.6698\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6012 - accuracy: 0.6608 - val_loss: 0.5923 - val_accuracy: 0.6707\n",
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6008 - accuracy: 0.6609 - val_loss: 0.5905 - val_accuracy: 0.6698\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6008 - accuracy: 0.6605 - val_loss: 0.5883 - val_accuracy: 0.6728\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5968 - accuracy: 0.6630 - val_loss: 0.5871 - val_accuracy: 0.6731\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5995 - accuracy: 0.6608 - val_loss: 0.5886 - val_accuracy: 0.6716\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5950 - accuracy: 0.6662 - val_loss: 0.5863 - val_accuracy: 0.6725\n",
      "Epoch 12/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5944 - accuracy: 0.6668 - val_loss: 0.5929 - val_accuracy: 0.6654\n",
      "Epoch 13/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5952 - accuracy: 0.6655 - val_loss: 0.5855 - val_accuracy: 0.6732\n",
      "Epoch 14/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5973 - accuracy: 0.6643 - val_loss: 0.5883 - val_accuracy: 0.6719\n",
      "Epoch 15/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5958 - accuracy: 0.6647 - val_loss: 0.5860 - val_accuracy: 0.6721\n",
      "Epoch 16/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5945 - accuracy: 0.6644 - val_loss: 0.5867 - val_accuracy: 0.6716\n",
      "Epoch 17/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5953 - accuracy: 0.6645 - val_loss: 0.5879 - val_accuracy: 0.6703\n",
      "Epoch 18/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5932 - accuracy: 0.6660 - val_loss: 0.5900 - val_accuracy: 0.6737\n",
      "2776/2776 [==============================] - 1s 328us/step - loss: 0.5901 - accuracy: 0.6664\n",
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6355 - accuracy: 0.6269 - val_loss: 0.6067 - val_accuracy: 0.6549\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6106 - accuracy: 0.6521 - val_loss: 0.6051 - val_accuracy: 0.6579\n",
      "Epoch 3/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6070 - accuracy: 0.6561 - val_loss: 0.6024 - val_accuracy: 0.6603\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6048 - accuracy: 0.6568 - val_loss: 0.6030 - val_accuracy: 0.6605\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.6010 - accuracy: 0.6579 - val_loss: 0.6005 - val_accuracy: 0.6610\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5992 - accuracy: 0.6610 - val_loss: 0.5987 - val_accuracy: 0.6632\n",
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5998 - accuracy: 0.6601 - val_loss: 0.6077 - val_accuracy: 0.6563\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5968 - accuracy: 0.6620 - val_loss: 0.6005 - val_accuracy: 0.6579\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5977 - accuracy: 0.6618 - val_loss: 0.6008 - val_accuracy: 0.6643\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5960 - accuracy: 0.6616 - val_loss: 0.5970 - val_accuracy: 0.6653\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5981 - accuracy: 0.6605 - val_loss: 0.5989 - val_accuracy: 0.6591\n",
      "Epoch 12/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5938 - accuracy: 0.6629 - val_loss: 0.6002 - val_accuracy: 0.6635\n",
      "Epoch 13/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5925 - accuracy: 0.6666 - val_loss: 0.5963 - val_accuracy: 0.6639\n",
      "Epoch 14/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5933 - accuracy: 0.6658 - val_loss: 0.5967 - val_accuracy: 0.6624\n",
      "Epoch 15/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5926 - accuracy: 0.6666 - val_loss: 0.5972 - val_accuracy: 0.6605\n",
      "Epoch 16/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5911 - accuracy: 0.6653 - val_loss: 0.5983 - val_accuracy: 0.6562\n",
      "Epoch 17/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5910 - accuracy: 0.6688 - val_loss: 0.5957 - val_accuracy: 0.6659\n",
      "Epoch 18/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5928 - accuracy: 0.6651 - val_loss: 0.5966 - val_accuracy: 0.6642\n",
      "Epoch 19/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5930 - accuracy: 0.6663 - val_loss: 0.5954 - val_accuracy: 0.6642\n",
      "Epoch 20/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5914 - accuracy: 0.6666 - val_loss: 0.5937 - val_accuracy: 0.6644\n",
      "Epoch 21/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5904 - accuracy: 0.6670 - val_loss: 0.5946 - val_accuracy: 0.6654\n",
      "Epoch 22/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5922 - accuracy: 0.6675 - val_loss: 0.5947 - val_accuracy: 0.6654\n",
      "Epoch 23/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5904 - accuracy: 0.6690 - val_loss: 0.5938 - val_accuracy: 0.6665\n",
      "Epoch 24/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5895 - accuracy: 0.6666 - val_loss: 0.5974 - val_accuracy: 0.6641\n",
      "Epoch 25/100\n",
      "4996/4996 [==============================] - 6s 1ms/step - loss: 0.5909 - accuracy: 0.6661 - val_loss: 0.5953 - val_accuracy: 0.6666\n",
      "2776/2776 [==============================] - 1s 330us/step - loss: 0.5879 - accuracy: 0.6702\n",
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 9s 1ms/step - loss: 0.6430 - accuracy: 0.6205 - val_loss: 0.6013 - val_accuracy: 0.6628\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6161 - accuracy: 0.6442 - val_loss: 0.6008 - val_accuracy: 0.6650\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6112 - accuracy: 0.6507 - val_loss: 0.5955 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6081 - accuracy: 0.6552 - val_loss: 0.5913 - val_accuracy: 0.6679\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6054 - accuracy: 0.6571 - val_loss: 0.5964 - val_accuracy: 0.6679\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6020 - accuracy: 0.6603 - val_loss: 0.6061 - val_accuracy: 0.6701\n",
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6008 - accuracy: 0.6599 - val_loss: 0.5945 - val_accuracy: 0.6666\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6021 - accuracy: 0.6595 - val_loss: 0.5886 - val_accuracy: 0.6732\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5983 - accuracy: 0.6630 - val_loss: 0.5898 - val_accuracy: 0.6698\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5988 - accuracy: 0.6626 - val_loss: 0.5893 - val_accuracy: 0.6697\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5982 - accuracy: 0.6614 - val_loss: 0.5887 - val_accuracy: 0.6721\n",
      "Epoch 12/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5971 - accuracy: 0.6621 - val_loss: 0.5906 - val_accuracy: 0.6687\n",
      "Epoch 13/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5958 - accuracy: 0.6656 - val_loss: 0.5866 - val_accuracy: 0.6691\n",
      "Epoch 14/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5960 - accuracy: 0.6651 - val_loss: 0.5906 - val_accuracy: 0.6697\n",
      "Epoch 15/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5961 - accuracy: 0.6652 - val_loss: 0.6046 - val_accuracy: 0.6625\n",
      "Epoch 16/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5950 - accuracy: 0.6657 - val_loss: 0.5864 - val_accuracy: 0.6736\n",
      "Epoch 17/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5946 - accuracy: 0.6643 - val_loss: 0.5868 - val_accuracy: 0.6730\n",
      "Epoch 18/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5935 - accuracy: 0.6673 - val_loss: 0.5906 - val_accuracy: 0.6735\n",
      "Epoch 19/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5932 - accuracy: 0.6677 - val_loss: 0.5849 - val_accuracy: 0.6720\n",
      "Epoch 20/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5925 - accuracy: 0.6651 - val_loss: 0.5897 - val_accuracy: 0.6720\n",
      "Epoch 21/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5936 - accuracy: 0.6663 - val_loss: 0.5894 - val_accuracy: 0.6732\n",
      "Epoch 22/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5925 - accuracy: 0.6664 - val_loss: 0.5895 - val_accuracy: 0.6712\n",
      "Epoch 23/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5907 - accuracy: 0.6682 - val_loss: 0.5880 - val_accuracy: 0.6725\n",
      "Epoch 24/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5894 - accuracy: 0.6679 - val_loss: 0.5907 - val_accuracy: 0.6697\n",
      "2776/2776 [==============================] - 1s 385us/step - loss: 0.5911 - accuracy: 0.6699\n",
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 8s 1ms/step - loss: 0.6408 - accuracy: 0.6227 - val_loss: 0.6064 - val_accuracy: 0.6561\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6177 - accuracy: 0.6435 - val_loss: 0.6012 - val_accuracy: 0.6655\n",
      "Epoch 3/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6092 - accuracy: 0.6540 - val_loss: 0.5935 - val_accuracy: 0.6680\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6068 - accuracy: 0.6557 - val_loss: 0.5922 - val_accuracy: 0.6689\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6052 - accuracy: 0.6572 - val_loss: 0.5924 - val_accuracy: 0.6677\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6029 - accuracy: 0.6604 - val_loss: 0.5914 - val_accuracy: 0.6715\n",
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6008 - accuracy: 0.6617 - val_loss: 0.5911 - val_accuracy: 0.6684\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5993 - accuracy: 0.6604 - val_loss: 0.5897 - val_accuracy: 0.6705\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5982 - accuracy: 0.6627 - val_loss: 0.5917 - val_accuracy: 0.6745\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5965 - accuracy: 0.6632 - val_loss: 0.5951 - val_accuracy: 0.6701\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5984 - accuracy: 0.6610 - val_loss: 0.5910 - val_accuracy: 0.6699\n",
      "Epoch 12/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5946 - accuracy: 0.6653 - val_loss: 0.6007 - val_accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5939 - accuracy: 0.6644 - val_loss: 0.5880 - val_accuracy: 0.6689\n",
      "Epoch 14/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5957 - accuracy: 0.6634 - val_loss: 0.5865 - val_accuracy: 0.6728\n",
      "Epoch 15/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5962 - accuracy: 0.6620 - val_loss: 0.5894 - val_accuracy: 0.6658\n",
      "Epoch 16/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5936 - accuracy: 0.6668 - val_loss: 0.5920 - val_accuracy: 0.6666\n",
      "Epoch 17/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5951 - accuracy: 0.6658 - val_loss: 0.5945 - val_accuracy: 0.6537\n",
      "Epoch 18/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5948 - accuracy: 0.6647 - val_loss: 0.5884 - val_accuracy: 0.6716\n",
      "Epoch 19/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5942 - accuracy: 0.6671 - val_loss: 0.5910 - val_accuracy: 0.6718\n",
      "2776/2776 [==============================] - 1s 383us/step - loss: 0.5907 - accuracy: 0.6664\n",
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 9s 1ms/step - loss: 0.6504 - accuracy: 0.6113 - val_loss: 0.6126 - val_accuracy: 0.6561\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6174 - accuracy: 0.6475 - val_loss: 0.6156 - val_accuracy: 0.6509\n",
      "Epoch 3/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6116 - accuracy: 0.6496 - val_loss: 0.6047 - val_accuracy: 0.6557\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6085 - accuracy: 0.6525 - val_loss: 0.6119 - val_accuracy: 0.6471\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6093 - accuracy: 0.6503 - val_loss: 0.6032 - val_accuracy: 0.6600\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6062 - accuracy: 0.6517 - val_loss: 0.5970 - val_accuracy: 0.6628\n",
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6038 - accuracy: 0.6575 - val_loss: 0.5973 - val_accuracy: 0.6628\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5996 - accuracy: 0.6597 - val_loss: 0.5975 - val_accuracy: 0.6635\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6024 - accuracy: 0.6566 - val_loss: 0.6002 - val_accuracy: 0.6621\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5997 - accuracy: 0.6581 - val_loss: 0.5959 - val_accuracy: 0.6623\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.6020 - accuracy: 0.6600 - val_loss: 0.5951 - val_accuracy: 0.6650\n",
      "Epoch 12/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5978 - accuracy: 0.6631 - val_loss: 0.5997 - val_accuracy: 0.6585\n",
      "Epoch 13/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5978 - accuracy: 0.6623 - val_loss: 0.5965 - val_accuracy: 0.6653\n",
      "Epoch 14/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5983 - accuracy: 0.6619 - val_loss: 0.5951 - val_accuracy: 0.6636\n",
      "Epoch 15/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5973 - accuracy: 0.6619 - val_loss: 0.5994 - val_accuracy: 0.6639\n",
      "Epoch 16/100\n",
      "4996/4996 [==============================] - 7s 1ms/step - loss: 0.5949 - accuracy: 0.6632 - val_loss: 0.5982 - val_accuracy: 0.6626\n",
      "2776/2776 [==============================] - 1s 384us/step - loss: 0.5902 - accuracy: 0.6687\n",
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 9s 2ms/step - loss: 0.6437 - accuracy: 0.6176 - val_loss: 0.6099 - val_accuracy: 0.6360\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6184 - accuracy: 0.6435 - val_loss: 0.5994 - val_accuracy: 0.6583\n",
      "Epoch 3/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6101 - accuracy: 0.6520 - val_loss: 0.5986 - val_accuracy: 0.6620\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6083 - accuracy: 0.6546 - val_loss: 0.6056 - val_accuracy: 0.6131\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6062 - accuracy: 0.6552 - val_loss: 0.5904 - val_accuracy: 0.6701\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6038 - accuracy: 0.6573 - val_loss: 0.5903 - val_accuracy: 0.6702\n",
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6016 - accuracy: 0.6609 - val_loss: 0.5922 - val_accuracy: 0.6696\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6030 - accuracy: 0.6569 - val_loss: 0.5937 - val_accuracy: 0.6724\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6018 - accuracy: 0.6594 - val_loss: 0.5915 - val_accuracy: 0.6692\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5962 - accuracy: 0.6632 - val_loss: 0.6093 - val_accuracy: 0.6294\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5988 - accuracy: 0.6623 - val_loss: 0.6009 - val_accuracy: 0.6593\n",
      "2776/2776 [==============================] - 1s 410us/step - loss: 0.5968 - accuracy: 0.6649\n",
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 9s 2ms/step - loss: 0.6385 - accuracy: 0.6237 - val_loss: 0.6062 - val_accuracy: 0.6647\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6169 - accuracy: 0.6479 - val_loss: 0.5994 - val_accuracy: 0.6595\n",
      "Epoch 3/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6122 - accuracy: 0.6533 - val_loss: 0.5986 - val_accuracy: 0.6663\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6084 - accuracy: 0.6574 - val_loss: 0.5927 - val_accuracy: 0.6650\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6064 - accuracy: 0.6598 - val_loss: 0.5942 - val_accuracy: 0.6668\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6036 - accuracy: 0.6593 - val_loss: 0.5914 - val_accuracy: 0.6691\n",
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6033 - accuracy: 0.6590 - val_loss: 0.5935 - val_accuracy: 0.6719\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6018 - accuracy: 0.6622 - val_loss: 0.5931 - val_accuracy: 0.6688\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6005 - accuracy: 0.6618 - val_loss: 0.5894 - val_accuracy: 0.6726\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5996 - accuracy: 0.6648 - val_loss: 0.5876 - val_accuracy: 0.6710\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5997 - accuracy: 0.6628 - val_loss: 0.5920 - val_accuracy: 0.6684\n",
      "Epoch 12/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5994 - accuracy: 0.6624 - val_loss: 0.5940 - val_accuracy: 0.6626\n",
      "Epoch 13/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5985 - accuracy: 0.6628 - val_loss: 0.5858 - val_accuracy: 0.6738\n",
      "Epoch 14/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5984 - accuracy: 0.6655 - val_loss: 0.5891 - val_accuracy: 0.6721\n",
      "Epoch 15/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5946 - accuracy: 0.6658 - val_loss: 0.5909 - val_accuracy: 0.6726\n",
      "Epoch 16/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5949 - accuracy: 0.6684 - val_loss: 0.5854 - val_accuracy: 0.6739\n",
      "Epoch 17/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5952 - accuracy: 0.6674 - val_loss: 0.5849 - val_accuracy: 0.6733\n",
      "Epoch 18/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5963 - accuracy: 0.6657 - val_loss: 0.5867 - val_accuracy: 0.6720\n",
      "Epoch 19/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5961 - accuracy: 0.6668 - val_loss: 0.5903 - val_accuracy: 0.6701\n",
      "Epoch 20/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5938 - accuracy: 0.6681 - val_loss: 0.5885 - val_accuracy: 0.6742\n",
      "Epoch 21/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5930 - accuracy: 0.6669 - val_loss: 0.5926 - val_accuracy: 0.6712\n",
      "Epoch 22/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5945 - accuracy: 0.6651 - val_loss: 0.5859 - val_accuracy: 0.6739\n",
      "2776/2776 [==============================] - 1s 397us/step - loss: 0.5908 - accuracy: 0.6682\n",
      "Epoch 1/100\n",
      "4996/4996 [==============================] - 9s 2ms/step - loss: 0.6417 - accuracy: 0.6188 - val_loss: 0.6094 - val_accuracy: 0.6526\n",
      "Epoch 2/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6139 - accuracy: 0.6474 - val_loss: 0.6053 - val_accuracy: 0.6571\n",
      "Epoch 3/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6106 - accuracy: 0.6516 - val_loss: 0.6070 - val_accuracy: 0.6543\n",
      "Epoch 4/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6076 - accuracy: 0.6532 - val_loss: 0.6034 - val_accuracy: 0.6577\n",
      "Epoch 5/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6055 - accuracy: 0.6534 - val_loss: 0.6030 - val_accuracy: 0.6601\n",
      "Epoch 6/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6052 - accuracy: 0.6521 - val_loss: 0.5988 - val_accuracy: 0.6617\n",
      "Epoch 7/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6006 - accuracy: 0.6582 - val_loss: 0.6001 - val_accuracy: 0.6582\n",
      "Epoch 8/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.6030 - accuracy: 0.6555 - val_loss: 0.5980 - val_accuracy: 0.6633\n",
      "Epoch 9/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5982 - accuracy: 0.6607 - val_loss: 0.5993 - val_accuracy: 0.6585\n",
      "Epoch 10/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5970 - accuracy: 0.6597 - val_loss: 0.5988 - val_accuracy: 0.6608\n",
      "Epoch 11/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5969 - accuracy: 0.6643 - val_loss: 0.5931 - val_accuracy: 0.6648\n",
      "Epoch 12/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5975 - accuracy: 0.6615 - val_loss: 0.5952 - val_accuracy: 0.6657\n",
      "Epoch 13/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5962 - accuracy: 0.6631 - val_loss: 0.5953 - val_accuracy: 0.6655\n",
      "Epoch 14/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5972 - accuracy: 0.6621 - val_loss: 0.5948 - val_accuracy: 0.6661\n",
      "Epoch 15/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5939 - accuracy: 0.6630 - val_loss: 0.6012 - val_accuracy: 0.6664\n",
      "Epoch 16/100\n",
      "4996/4996 [==============================] - 8s 2ms/step - loss: 0.5942 - accuracy: 0.6636 - val_loss: 0.5964 - val_accuracy: 0.6598\n",
      "2776/2776 [==============================] - 1s 405us/step - loss: 0.5901 - accuracy: 0.6688\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 3s 835us/step - loss: 0.6276 - accuracy: 0.6321 - val_loss: 0.5992 - val_accuracy: 0.6622\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 2s 703us/step - loss: 0.6065 - accuracy: 0.6519 - val_loss: 0.5930 - val_accuracy: 0.6689\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 2s 706us/step - loss: 0.6016 - accuracy: 0.6572 - val_loss: 0.5976 - val_accuracy: 0.6570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 2s 714us/step - loss: 0.5985 - accuracy: 0.6592 - val_loss: 0.5876 - val_accuracy: 0.6681\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 2s 712us/step - loss: 0.5959 - accuracy: 0.6617 - val_loss: 0.5877 - val_accuracy: 0.6703\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 2s 711us/step - loss: 0.5966 - accuracy: 0.6620 - val_loss: 0.5893 - val_accuracy: 0.6688\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 2s 711us/step - loss: 0.5970 - accuracy: 0.6629 - val_loss: 0.5854 - val_accuracy: 0.6674\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 2s 709us/step - loss: 0.5928 - accuracy: 0.6626 - val_loss: 0.5873 - val_accuracy: 0.6719\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 2s 718us/step - loss: 0.5933 - accuracy: 0.6638 - val_loss: 0.5854 - val_accuracy: 0.6688\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 2s 712us/step - loss: 0.5936 - accuracy: 0.6632 - val_loss: 0.5845 - val_accuracy: 0.6707\n",
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 2s 714us/step - loss: 0.5936 - accuracy: 0.6635 - val_loss: 0.5855 - val_accuracy: 0.6696\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 2s 704us/step - loss: 0.5935 - accuracy: 0.6643 - val_loss: 0.5881 - val_accuracy: 0.6693\n",
      "Epoch 13/100\n",
      "3123/3123 [==============================] - 2s 708us/step - loss: 0.5934 - accuracy: 0.6649 - val_loss: 0.5869 - val_accuracy: 0.6730\n",
      "Epoch 14/100\n",
      "3123/3123 [==============================] - 2s 704us/step - loss: 0.5913 - accuracy: 0.6642 - val_loss: 0.5863 - val_accuracy: 0.6697\n",
      "Epoch 15/100\n",
      "3123/3123 [==============================] - 2s 700us/step - loss: 0.5897 - accuracy: 0.6663 - val_loss: 0.5846 - val_accuracy: 0.6718\n",
      "1735/1735 [==============================] - 0s 262us/step - loss: 0.5903 - accuracy: 0.6687\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 3s 746us/step - loss: 0.6301 - accuracy: 0.6347 - val_loss: 0.6014 - val_accuracy: 0.6567\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 2s 707us/step - loss: 0.6045 - accuracy: 0.6575 - val_loss: 0.5929 - val_accuracy: 0.6686\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 2s 720us/step - loss: 0.6016 - accuracy: 0.6594 - val_loss: 0.5916 - val_accuracy: 0.6696\n",
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 2s 717us/step - loss: 0.5993 - accuracy: 0.6611 - val_loss: 0.5889 - val_accuracy: 0.6733\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 2s 711us/step - loss: 0.5987 - accuracy: 0.6598 - val_loss: 0.5867 - val_accuracy: 0.6714\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 2s 707us/step - loss: 0.5973 - accuracy: 0.6627 - val_loss: 0.5856 - val_accuracy: 0.6723\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 2s 719us/step - loss: 0.5957 - accuracy: 0.6640 - val_loss: 0.5845 - val_accuracy: 0.6760\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 2s 708us/step - loss: 0.5935 - accuracy: 0.6645 - val_loss: 0.5855 - val_accuracy: 0.6732\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 2s 711us/step - loss: 0.5943 - accuracy: 0.6652 - val_loss: 0.5849 - val_accuracy: 0.6733\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 2s 714us/step - loss: 0.5927 - accuracy: 0.6667 - val_loss: 0.5835 - val_accuracy: 0.6742\n",
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 2s 711us/step - loss: 0.5919 - accuracy: 0.6659 - val_loss: 0.5854 - val_accuracy: 0.6737\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 2s 708us/step - loss: 0.5922 - accuracy: 0.6668 - val_loss: 0.5858 - val_accuracy: 0.6739\n",
      "Epoch 13/100\n",
      "3123/3123 [==============================] - 2s 712us/step - loss: 0.5898 - accuracy: 0.6684 - val_loss: 0.5869 - val_accuracy: 0.6753\n",
      "Epoch 14/100\n",
      "3123/3123 [==============================] - 2s 708us/step - loss: 0.5899 - accuracy: 0.6688 - val_loss: 0.5836 - val_accuracy: 0.6742\n",
      "Epoch 15/100\n",
      "3123/3123 [==============================] - 2s 708us/step - loss: 0.5894 - accuracy: 0.6702 - val_loss: 0.5848 - val_accuracy: 0.6745\n",
      "1735/1735 [==============================] - 0s 255us/step - loss: 0.5893 - accuracy: 0.6664\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 3s 750us/step - loss: 0.6319 - accuracy: 0.6324 - val_loss: 0.6035 - val_accuracy: 0.6583\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 2s 719us/step - loss: 0.6035 - accuracy: 0.6555 - val_loss: 0.6011 - val_accuracy: 0.6626\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 2s 718us/step - loss: 0.6010 - accuracy: 0.6602 - val_loss: 0.5969 - val_accuracy: 0.6578\n",
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 2s 714us/step - loss: 0.5997 - accuracy: 0.6585 - val_loss: 0.5972 - val_accuracy: 0.6611\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 2s 716us/step - loss: 0.5964 - accuracy: 0.6610 - val_loss: 0.5954 - val_accuracy: 0.6653\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 2s 713us/step - loss: 0.5952 - accuracy: 0.6628 - val_loss: 0.5951 - val_accuracy: 0.6660\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 2s 716us/step - loss: 0.5948 - accuracy: 0.6646 - val_loss: 0.5970 - val_accuracy: 0.6636\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 2s 712us/step - loss: 0.5948 - accuracy: 0.6638 - val_loss: 0.5948 - val_accuracy: 0.6619\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 2s 718us/step - loss: 0.5930 - accuracy: 0.6622 - val_loss: 0.5936 - val_accuracy: 0.6661\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 2s 714us/step - loss: 0.5924 - accuracy: 0.6668 - val_loss: 0.5937 - val_accuracy: 0.6644\n",
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 2s 713us/step - loss: 0.5913 - accuracy: 0.6664 - val_loss: 0.5949 - val_accuracy: 0.6642\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 2s 714us/step - loss: 0.5917 - accuracy: 0.6646 - val_loss: 0.5925 - val_accuracy: 0.6665\n",
      "Epoch 13/100\n",
      "3123/3123 [==============================] - 2s 714us/step - loss: 0.5934 - accuracy: 0.6644 - val_loss: 0.5939 - val_accuracy: 0.6659\n",
      "Epoch 14/100\n",
      "3123/3123 [==============================] - 2s 717us/step - loss: 0.5885 - accuracy: 0.6693 - val_loss: 0.5949 - val_accuracy: 0.6611\n",
      "Epoch 15/100\n",
      "3123/3123 [==============================] - 2s 713us/step - loss: 0.5911 - accuracy: 0.6655 - val_loss: 0.5938 - val_accuracy: 0.6668\n",
      "Epoch 16/100\n",
      "3123/3123 [==============================] - 2s 715us/step - loss: 0.5888 - accuracy: 0.6679 - val_loss: 0.5946 - val_accuracy: 0.6650\n",
      "Epoch 17/100\n",
      "3123/3123 [==============================] - 2s 701us/step - loss: 0.5879 - accuracy: 0.6703 - val_loss: 0.5946 - val_accuracy: 0.6629\n",
      "1735/1735 [==============================] - 0s 256us/step - loss: 0.5876 - accuracy: 0.6715\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 3s 774us/step - loss: 0.6294 - accuracy: 0.6298 - val_loss: 0.5961 - val_accuracy: 0.6660\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 2s 739us/step - loss: 0.6059 - accuracy: 0.6547 - val_loss: 0.5900 - val_accuracy: 0.6652\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 2s 740us/step - loss: 0.5980 - accuracy: 0.6594 - val_loss: 0.5898 - val_accuracy: 0.6688\n",
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 2s 737us/step - loss: 0.5984 - accuracy: 0.6597 - val_loss: 0.5878 - val_accuracy: 0.6713\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 2s 733us/step - loss: 0.5961 - accuracy: 0.6618 - val_loss: 0.5869 - val_accuracy: 0.6707\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 2s 740us/step - loss: 0.5956 - accuracy: 0.6625 - val_loss: 0.5873 - val_accuracy: 0.6726\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 2s 745us/step - loss: 0.5960 - accuracy: 0.6598 - val_loss: 0.5868 - val_accuracy: 0.6717\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 2s 737us/step - loss: 0.5918 - accuracy: 0.6647 - val_loss: 0.5893 - val_accuracy: 0.6683\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 2s 742us/step - loss: 0.5920 - accuracy: 0.6657 - val_loss: 0.5888 - val_accuracy: 0.6636\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 2s 739us/step - loss: 0.5890 - accuracy: 0.6675 - val_loss: 0.5886 - val_accuracy: 0.6719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 2s 747us/step - loss: 0.5916 - accuracy: 0.6666 - val_loss: 0.5886 - val_accuracy: 0.6689\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 2s 749us/step - loss: 0.5924 - accuracy: 0.6637 - val_loss: 0.5870 - val_accuracy: 0.6734\n",
      "1735/1735 [==============================] - 0s 274us/step - loss: 0.5933 - accuracy: 0.6677\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 3s 791us/step - loss: 0.6289 - accuracy: 0.6324 - val_loss: 0.5985 - val_accuracy: 0.6635\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 3s 806us/step - loss: 0.6057 - accuracy: 0.6545 - val_loss: 0.5912 - val_accuracy: 0.6647\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 3s 846us/step - loss: 0.6006 - accuracy: 0.6589 - val_loss: 0.5893 - val_accuracy: 0.6696\n",
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 2s 763us/step - loss: 0.5966 - accuracy: 0.6616 - val_loss: 0.5892 - val_accuracy: 0.6695\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 2s 772us/step - loss: 0.5962 - accuracy: 0.6623 - val_loss: 0.5894 - val_accuracy: 0.6685\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 2s 777us/step - loss: 0.5974 - accuracy: 0.6627 - val_loss: 0.5865 - val_accuracy: 0.6702\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 2s 772us/step - loss: 0.5966 - accuracy: 0.6608 - val_loss: 0.5865 - val_accuracy: 0.6717\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 2s 786us/step - loss: 0.5954 - accuracy: 0.6640 - val_loss: 0.5854 - val_accuracy: 0.6721\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 2s 775us/step - loss: 0.5928 - accuracy: 0.6659 - val_loss: 0.5867 - val_accuracy: 0.6688\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 2s 775us/step - loss: 0.5921 - accuracy: 0.6682 - val_loss: 0.5878 - val_accuracy: 0.6698\n",
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 2s 780us/step - loss: 0.5918 - accuracy: 0.6673 - val_loss: 0.5851 - val_accuracy: 0.6728\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 2s 777us/step - loss: 0.5933 - accuracy: 0.6666 - val_loss: 0.5856 - val_accuracy: 0.6707\n",
      "Epoch 13/100\n",
      "3123/3123 [==============================] - 2s 780us/step - loss: 0.5925 - accuracy: 0.6640 - val_loss: 0.5842 - val_accuracy: 0.6740\n",
      "Epoch 14/100\n",
      "3123/3123 [==============================] - 2s 784us/step - loss: 0.5933 - accuracy: 0.6658 - val_loss: 0.5859 - val_accuracy: 0.6736\n",
      "Epoch 15/100\n",
      "3123/3123 [==============================] - 2s 769us/step - loss: 0.5919 - accuracy: 0.6655 - val_loss: 0.5849 - val_accuracy: 0.6726\n",
      "Epoch 16/100\n",
      "3123/3123 [==============================] - 2s 777us/step - loss: 0.5921 - accuracy: 0.6681 - val_loss: 0.5860 - val_accuracy: 0.6722\n",
      "Epoch 17/100\n",
      "3123/3123 [==============================] - 2s 774us/step - loss: 0.5914 - accuracy: 0.6683 - val_loss: 0.5835 - val_accuracy: 0.6727\n",
      "Epoch 18/100\n",
      "3123/3123 [==============================] - 2s 777us/step - loss: 0.5913 - accuracy: 0.6669 - val_loss: 0.5826 - val_accuracy: 0.6736\n",
      "Epoch 19/100\n",
      "3123/3123 [==============================] - 2s 785us/step - loss: 0.5917 - accuracy: 0.6653 - val_loss: 0.5828 - val_accuracy: 0.6736\n",
      "Epoch 20/100\n",
      "3123/3123 [==============================] - 3s 802us/step - loss: 0.5899 - accuracy: 0.6665 - val_loss: 0.5883 - val_accuracy: 0.6704\n",
      "Epoch 21/100\n",
      "3123/3123 [==============================] - 2s 770us/step - loss: 0.5892 - accuracy: 0.6700 - val_loss: 0.5846 - val_accuracy: 0.6716\n",
      "Epoch 22/100\n",
      "3123/3123 [==============================] - 2s 794us/step - loss: 0.5900 - accuracy: 0.6688 - val_loss: 0.5831 - val_accuracy: 0.6719\n",
      "Epoch 23/100\n",
      "3123/3123 [==============================] - 2s 787us/step - loss: 0.5896 - accuracy: 0.6685 - val_loss: 0.5828 - val_accuracy: 0.6713\n",
      "1735/1735 [==============================] - 1s 285us/step - loss: 0.5878 - accuracy: 0.6677\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 3s 803us/step - loss: 0.6337 - accuracy: 0.6293 - val_loss: 0.6056 - val_accuracy: 0.6474\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 2s 763us/step - loss: 0.6066 - accuracy: 0.6520 - val_loss: 0.6043 - val_accuracy: 0.6558\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 2s 763us/step - loss: 0.6014 - accuracy: 0.6567 - val_loss: 0.6005 - val_accuracy: 0.6594\n",
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 2s 762us/step - loss: 0.5997 - accuracy: 0.6579 - val_loss: 0.5997 - val_accuracy: 0.6571\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 2s 775us/step - loss: 0.5978 - accuracy: 0.6600 - val_loss: 0.6034 - val_accuracy: 0.6455\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 2s 756us/step - loss: 0.5980 - accuracy: 0.6626 - val_loss: 0.5966 - val_accuracy: 0.6618\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 2s 741us/step - loss: 0.5943 - accuracy: 0.6633 - val_loss: 0.5953 - val_accuracy: 0.6641\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 2s 735us/step - loss: 0.5926 - accuracy: 0.6653 - val_loss: 0.5943 - val_accuracy: 0.6624\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 2s 739us/step - loss: 0.5943 - accuracy: 0.6629 - val_loss: 0.5961 - val_accuracy: 0.6655\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 2s 738us/step - loss: 0.5939 - accuracy: 0.6645 - val_loss: 0.5949 - val_accuracy: 0.6645\n",
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 2s 737us/step - loss: 0.5919 - accuracy: 0.6658 - val_loss: 0.5951 - val_accuracy: 0.6622\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 2s 739us/step - loss: 0.5898 - accuracy: 0.6679 - val_loss: 0.5977 - val_accuracy: 0.6588\n",
      "Epoch 13/100\n",
      "3123/3123 [==============================] - 3s 833us/step - loss: 0.5948 - accuracy: 0.6655 - val_loss: 0.5940 - val_accuracy: 0.6637\n",
      "Epoch 14/100\n",
      "3123/3123 [==============================] - 2s 781us/step - loss: 0.5912 - accuracy: 0.6678 - val_loss: 0.5934 - val_accuracy: 0.6683\n",
      "Epoch 15/100\n",
      "3123/3123 [==============================] - 2s 759us/step - loss: 0.5915 - accuracy: 0.6687 - val_loss: 0.5939 - val_accuracy: 0.6652\n",
      "Epoch 16/100\n",
      "3123/3123 [==============================] - 2s 768us/step - loss: 0.5893 - accuracy: 0.6683 - val_loss: 0.5940 - val_accuracy: 0.6653\n",
      "Epoch 17/100\n",
      "3123/3123 [==============================] - 2s 764us/step - loss: 0.5914 - accuracy: 0.6649 - val_loss: 0.5920 - val_accuracy: 0.6675\n",
      "Epoch 18/100\n",
      "3123/3123 [==============================] - 2s 744us/step - loss: 0.5896 - accuracy: 0.6679 - val_loss: 0.5938 - val_accuracy: 0.6662\n",
      "Epoch 19/100\n",
      "3123/3123 [==============================] - 2s 745us/step - loss: 0.5895 - accuracy: 0.6667 - val_loss: 0.5925 - val_accuracy: 0.6661\n",
      "Epoch 20/100\n",
      "3123/3123 [==============================] - 2s 748us/step - loss: 0.5879 - accuracy: 0.6682 - val_loss: 0.5928 - val_accuracy: 0.6639\n",
      "Epoch 21/100\n",
      "3123/3123 [==============================] - 2s 749us/step - loss: 0.5896 - accuracy: 0.6670 - val_loss: 0.5926 - val_accuracy: 0.6653\n",
      "Epoch 22/100\n",
      "3123/3123 [==============================] - 2s 743us/step - loss: 0.5884 - accuracy: 0.6688 - val_loss: 0.5909 - val_accuracy: 0.6668\n",
      "Epoch 23/100\n",
      "3123/3123 [==============================] - 2s 765us/step - loss: 0.5900 - accuracy: 0.6681 - val_loss: 0.5915 - val_accuracy: 0.6672\n",
      "Epoch 24/100\n",
      "3123/3123 [==============================] - 2s 750us/step - loss: 0.5920 - accuracy: 0.6653 - val_loss: 0.5925 - val_accuracy: 0.6676\n",
      "Epoch 25/100\n",
      "3123/3123 [==============================] - 2s 764us/step - loss: 0.5885 - accuracy: 0.6688 - val_loss: 0.5909 - val_accuracy: 0.6662\n",
      "Epoch 26/100\n",
      "3123/3123 [==============================] - 2s 747us/step - loss: 0.5893 - accuracy: 0.6674 - val_loss: 0.5920 - val_accuracy: 0.6688\n",
      "Epoch 27/100\n",
      "3123/3123 [==============================] - 2s 744us/step - loss: 0.5896 - accuracy: 0.6654 - val_loss: 0.5916 - val_accuracy: 0.6680\n",
      "Epoch 28/100\n",
      "3123/3123 [==============================] - 2s 748us/step - loss: 0.5847 - accuracy: 0.6708 - val_loss: 0.5945 - val_accuracy: 0.6654\n",
      "Epoch 29/100\n",
      "3123/3123 [==============================] - 2s 755us/step - loss: 0.5889 - accuracy: 0.6669 - val_loss: 0.5931 - val_accuracy: 0.6672\n",
      "Epoch 30/100\n",
      "3123/3123 [==============================] - 2s 753us/step - loss: 0.5892 - accuracy: 0.6665 - val_loss: 0.5915 - val_accuracy: 0.6686\n",
      "1735/1735 [==============================] - 0s 271us/step - loss: 0.5868 - accuracy: 0.6710\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 5s 1ms/step - loss: 0.6282 - accuracy: 0.6363 - val_loss: 0.6003 - val_accuracy: 0.6582\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.6088 - accuracy: 0.6526 - val_loss: 0.6076 - val_accuracy: 0.6654\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.6035 - accuracy: 0.6578 - val_loss: 0.5931 - val_accuracy: 0.6700\n",
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5998 - accuracy: 0.6588 - val_loss: 0.5930 - val_accuracy: 0.6678\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5985 - accuracy: 0.6626 - val_loss: 0.5895 - val_accuracy: 0.6702\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5987 - accuracy: 0.6592 - val_loss: 0.5943 - val_accuracy: 0.6639\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5975 - accuracy: 0.6597 - val_loss: 0.5867 - val_accuracy: 0.6733\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5941 - accuracy: 0.6653 - val_loss: 0.5871 - val_accuracy: 0.6701\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5939 - accuracy: 0.6630 - val_loss: 0.5852 - val_accuracy: 0.6734\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5943 - accuracy: 0.6608 - val_loss: 0.5875 - val_accuracy: 0.6719\n",
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5948 - accuracy: 0.6637 - val_loss: 0.5878 - val_accuracy: 0.6635\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5936 - accuracy: 0.6633 - val_loss: 0.5861 - val_accuracy: 0.6717\n",
      "Epoch 13/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5920 - accuracy: 0.6636 - val_loss: 0.5894 - val_accuracy: 0.6695\n",
      "Epoch 14/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5928 - accuracy: 0.6642 - val_loss: 0.5862 - val_accuracy: 0.6734\n",
      "1735/1735 [==============================] - 1s 347us/step - loss: 0.5932 - accuracy: 0.6695\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 5s 1ms/step - loss: 0.6335 - accuracy: 0.6289 - val_loss: 0.5983 - val_accuracy: 0.6605\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.6086 - accuracy: 0.6551 - val_loss: 0.5948 - val_accuracy: 0.6671\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.6056 - accuracy: 0.6537 - val_loss: 0.5918 - val_accuracy: 0.6668\n",
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5995 - accuracy: 0.6635 - val_loss: 0.5888 - val_accuracy: 0.6668\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5983 - accuracy: 0.6625 - val_loss: 0.5908 - val_accuracy: 0.6710\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5972 - accuracy: 0.6646 - val_loss: 0.5884 - val_accuracy: 0.6620\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5959 - accuracy: 0.6669 - val_loss: 0.5867 - val_accuracy: 0.6723\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5954 - accuracy: 0.6672 - val_loss: 0.5893 - val_accuracy: 0.6675\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5935 - accuracy: 0.6662 - val_loss: 0.5909 - val_accuracy: 0.6671\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5913 - accuracy: 0.6691 - val_loss: 0.5887 - val_accuracy: 0.6655\n",
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5928 - accuracy: 0.6650 - val_loss: 0.5837 - val_accuracy: 0.6735\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5922 - accuracy: 0.6680 - val_loss: 0.5839 - val_accuracy: 0.6750\n",
      "Epoch 13/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5931 - accuracy: 0.6678 - val_loss: 0.5854 - val_accuracy: 0.6734\n",
      "Epoch 14/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5932 - accuracy: 0.6642 - val_loss: 0.5884 - val_accuracy: 0.6739\n",
      "Epoch 15/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5927 - accuracy: 0.6659 - val_loss: 0.5882 - val_accuracy: 0.6690\n",
      "Epoch 16/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5906 - accuracy: 0.6687 - val_loss: 0.5848 - val_accuracy: 0.6756\n",
      "1735/1735 [==============================] - 1s 333us/step - loss: 0.5891 - accuracy: 0.6670\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 5s 1ms/step - loss: 0.6346 - accuracy: 0.6299 - val_loss: 0.6058 - val_accuracy: 0.6590\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.6076 - accuracy: 0.6569 - val_loss: 0.6038 - val_accuracy: 0.6569\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.6042 - accuracy: 0.6552 - val_loss: 0.5992 - val_accuracy: 0.6606\n",
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.6009 - accuracy: 0.6600 - val_loss: 0.5969 - val_accuracy: 0.6624\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.6011 - accuracy: 0.6603 - val_loss: 0.5977 - val_accuracy: 0.6568\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5979 - accuracy: 0.6611 - val_loss: 0.5975 - val_accuracy: 0.6569\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5982 - accuracy: 0.6583 - val_loss: 0.5943 - val_accuracy: 0.6621\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5950 - accuracy: 0.6636 - val_loss: 0.5943 - val_accuracy: 0.6649\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5934 - accuracy: 0.6657 - val_loss: 0.5949 - val_accuracy: 0.6607\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5962 - accuracy: 0.6632 - val_loss: 0.5944 - val_accuracy: 0.6608\n",
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5954 - accuracy: 0.6622 - val_loss: 0.5975 - val_accuracy: 0.6594\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5947 - accuracy: 0.6651 - val_loss: 0.5940 - val_accuracy: 0.6655\n",
      "Epoch 13/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5930 - accuracy: 0.6671 - val_loss: 0.5938 - val_accuracy: 0.6627\n",
      "Epoch 14/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5909 - accuracy: 0.6681 - val_loss: 0.5938 - val_accuracy: 0.6680\n",
      "Epoch 15/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5923 - accuracy: 0.6666 - val_loss: 0.5960 - val_accuracy: 0.6632\n",
      "Epoch 16/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5897 - accuracy: 0.6684 - val_loss: 0.5938 - val_accuracy: 0.6634\n",
      "Epoch 17/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5930 - accuracy: 0.6627 - val_loss: 0.5941 - val_accuracy: 0.6651\n",
      "Epoch 18/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5912 - accuracy: 0.6671 - val_loss: 0.5927 - val_accuracy: 0.6641\n",
      "Epoch 19/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5922 - accuracy: 0.6647 - val_loss: 0.5945 - val_accuracy: 0.6653\n",
      "Epoch 20/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5905 - accuracy: 0.6667 - val_loss: 0.5943 - val_accuracy: 0.6679\n",
      "Epoch 21/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5915 - accuracy: 0.6668 - val_loss: 0.5938 - val_accuracy: 0.6655\n",
      "Epoch 22/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5910 - accuracy: 0.6673 - val_loss: 0.5979 - val_accuracy: 0.6570\n",
      "Epoch 23/100\n",
      "3123/3123 [==============================] - 3s 1ms/step - loss: 0.5899 - accuracy: 0.6685 - val_loss: 0.5964 - val_accuracy: 0.6653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1735/1735 [==============================] - 1s 345us/step - loss: 0.5873 - accuracy: 0.6710\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 5s 1ms/step - loss: 0.6376 - accuracy: 0.6251 - val_loss: 0.6066 - val_accuracy: 0.6566\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.6079 - accuracy: 0.6533 - val_loss: 0.5965 - val_accuracy: 0.6660\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.6027 - accuracy: 0.6601 - val_loss: 0.5906 - val_accuracy: 0.6683\n",
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.6009 - accuracy: 0.6590 - val_loss: 0.5896 - val_accuracy: 0.6704\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5991 - accuracy: 0.6609 - val_loss: 0.5875 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5955 - accuracy: 0.6642 - val_loss: 0.5903 - val_accuracy: 0.6648\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5945 - accuracy: 0.6636 - val_loss: 0.5874 - val_accuracy: 0.6733\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5965 - accuracy: 0.6624 - val_loss: 0.5870 - val_accuracy: 0.6696\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5923 - accuracy: 0.6662 - val_loss: 0.5866 - val_accuracy: 0.6725\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5935 - accuracy: 0.6666 - val_loss: 0.5867 - val_accuracy: 0.6717\n",
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5908 - accuracy: 0.6651 - val_loss: 0.5847 - val_accuracy: 0.6714\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5900 - accuracy: 0.6667 - val_loss: 0.5841 - val_accuracy: 0.6717\n",
      "Epoch 13/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5922 - accuracy: 0.6641 - val_loss: 0.5888 - val_accuracy: 0.6626\n",
      "Epoch 14/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5921 - accuracy: 0.6644 - val_loss: 0.5834 - val_accuracy: 0.6743\n",
      "Epoch 15/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5915 - accuracy: 0.6670 - val_loss: 0.5827 - val_accuracy: 0.6733\n",
      "Epoch 16/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5887 - accuracy: 0.6687 - val_loss: 0.5850 - val_accuracy: 0.6744\n",
      "Epoch 17/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5911 - accuracy: 0.6658 - val_loss: 0.5828 - val_accuracy: 0.6746\n",
      "Epoch 18/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5903 - accuracy: 0.6640 - val_loss: 0.5855 - val_accuracy: 0.6760\n",
      "Epoch 19/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5896 - accuracy: 0.6677 - val_loss: 0.5835 - val_accuracy: 0.6731\n",
      "Epoch 20/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5888 - accuracy: 0.6666 - val_loss: 0.5866 - val_accuracy: 0.6686\n",
      "1735/1735 [==============================] - 1s 361us/step - loss: 0.5895 - accuracy: 0.6694\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 5s 1ms/step - loss: 0.6363 - accuracy: 0.6238 - val_loss: 0.6018 - val_accuracy: 0.6662\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.6068 - accuracy: 0.6539 - val_loss: 0.5923 - val_accuracy: 0.6689\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.6003 - accuracy: 0.6618 - val_loss: 0.5906 - val_accuracy: 0.6686\n",
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5977 - accuracy: 0.6645 - val_loss: 0.5905 - val_accuracy: 0.6671\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5992 - accuracy: 0.6606 - val_loss: 0.5914 - val_accuracy: 0.6713\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5977 - accuracy: 0.6631 - val_loss: 0.5891 - val_accuracy: 0.6722\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5972 - accuracy: 0.6634 - val_loss: 0.5882 - val_accuracy: 0.6728\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5959 - accuracy: 0.6646 - val_loss: 0.5857 - val_accuracy: 0.6713\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5966 - accuracy: 0.6624 - val_loss: 0.5856 - val_accuracy: 0.6738\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5946 - accuracy: 0.6649 - val_loss: 0.5855 - val_accuracy: 0.6712\n",
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5932 - accuracy: 0.6663 - val_loss: 0.5844 - val_accuracy: 0.6728\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5934 - accuracy: 0.6665 - val_loss: 0.5858 - val_accuracy: 0.6735\n",
      "Epoch 13/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5920 - accuracy: 0.6651 - val_loss: 0.5910 - val_accuracy: 0.6663\n",
      "Epoch 14/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5906 - accuracy: 0.6680 - val_loss: 0.5854 - val_accuracy: 0.6723\n",
      "Epoch 15/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5911 - accuracy: 0.6663 - val_loss: 0.5877 - val_accuracy: 0.6741\n",
      "Epoch 16/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5906 - accuracy: 0.6671 - val_loss: 0.5855 - val_accuracy: 0.6714\n",
      "1735/1735 [==============================] - 1s 353us/step - loss: 0.5904 - accuracy: 0.6671\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 5s 1ms/step - loss: 0.6328 - accuracy: 0.6247 - val_loss: 0.6072 - val_accuracy: 0.6529\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.6098 - accuracy: 0.6512 - val_loss: 0.6057 - val_accuracy: 0.6552\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.6054 - accuracy: 0.6530 - val_loss: 0.6009 - val_accuracy: 0.6581\n",
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5989 - accuracy: 0.6627 - val_loss: 0.5991 - val_accuracy: 0.6610\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5994 - accuracy: 0.6596 - val_loss: 0.6003 - val_accuracy: 0.6654\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5974 - accuracy: 0.6627 - val_loss: 0.6021 - val_accuracy: 0.6547\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5957 - accuracy: 0.6628 - val_loss: 0.5944 - val_accuracy: 0.6627\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5940 - accuracy: 0.6664 - val_loss: 0.5984 - val_accuracy: 0.6609\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5967 - accuracy: 0.6614 - val_loss: 0.5958 - val_accuracy: 0.6581\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5948 - accuracy: 0.6660 - val_loss: 0.5925 - val_accuracy: 0.6697\n",
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5951 - accuracy: 0.6639 - val_loss: 0.5954 - val_accuracy: 0.6649\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5918 - accuracy: 0.6693 - val_loss: 0.5948 - val_accuracy: 0.6648\n",
      "Epoch 13/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5938 - accuracy: 0.6644 - val_loss: 0.5959 - val_accuracy: 0.6645\n",
      "Epoch 14/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5917 - accuracy: 0.6670 - val_loss: 0.5948 - val_accuracy: 0.6656\n",
      "Epoch 15/100\n",
      "3123/3123 [==============================] - 4s 1ms/step - loss: 0.5907 - accuracy: 0.6681 - val_loss: 0.5938 - val_accuracy: 0.6639\n",
      "1735/1735 [==============================] - 1s 353us/step - loss: 0.5881 - accuracy: 0.6713\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 6s 2ms/step - loss: 0.6400 - accuracy: 0.6199 - val_loss: 0.6042 - val_accuracy: 0.6600\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6109 - accuracy: 0.6505 - val_loss: 0.6012 - val_accuracy: 0.6649\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6079 - accuracy: 0.6555 - val_loss: 0.5954 - val_accuracy: 0.6678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6023 - accuracy: 0.6590 - val_loss: 0.5942 - val_accuracy: 0.6695\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6021 - accuracy: 0.6573 - val_loss: 0.5933 - val_accuracy: 0.6729\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6019 - accuracy: 0.6578 - val_loss: 0.5876 - val_accuracy: 0.6721\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5976 - accuracy: 0.6632 - val_loss: 0.5881 - val_accuracy: 0.6683\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5954 - accuracy: 0.6618 - val_loss: 0.5887 - val_accuracy: 0.6718\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5946 - accuracy: 0.6648 - val_loss: 0.5896 - val_accuracy: 0.6671\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5961 - accuracy: 0.6631 - val_loss: 0.5869 - val_accuracy: 0.6740\n",
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 5s 1ms/step - loss: 0.5940 - accuracy: 0.6636 - val_loss: 0.5837 - val_accuracy: 0.6735\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5922 - accuracy: 0.6657 - val_loss: 0.5871 - val_accuracy: 0.6716\n",
      "Epoch 13/100\n",
      "3123/3123 [==============================] - 5s 1ms/step - loss: 0.5917 - accuracy: 0.6660 - val_loss: 0.5841 - val_accuracy: 0.6744\n",
      "Epoch 14/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5945 - accuracy: 0.6637 - val_loss: 0.5877 - val_accuracy: 0.6735\n",
      "Epoch 15/100\n",
      "3123/3123 [==============================] - 5s 1ms/step - loss: 0.5926 - accuracy: 0.6656 - val_loss: 0.5852 - val_accuracy: 0.6716\n",
      "Epoch 16/100\n",
      "3123/3123 [==============================] - 5s 1ms/step - loss: 0.5920 - accuracy: 0.6665 - val_loss: 0.5848 - val_accuracy: 0.6728\n",
      "1735/1735 [==============================] - 1s 426us/step - loss: 0.5910 - accuracy: 0.6681\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 7s 2ms/step - loss: 0.6370 - accuracy: 0.6272 - val_loss: 0.6025 - val_accuracy: 0.6617\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6127 - accuracy: 0.6519 - val_loss: 0.6005 - val_accuracy: 0.6668\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6107 - accuracy: 0.6510 - val_loss: 0.5996 - val_accuracy: 0.6655\n",
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6054 - accuracy: 0.6576 - val_loss: 0.5917 - val_accuracy: 0.6647\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6028 - accuracy: 0.6593 - val_loss: 0.5933 - val_accuracy: 0.6678\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6015 - accuracy: 0.6593 - val_loss: 0.5881 - val_accuracy: 0.6725\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5990 - accuracy: 0.6611 - val_loss: 0.5889 - val_accuracy: 0.6678\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5956 - accuracy: 0.6620 - val_loss: 0.5889 - val_accuracy: 0.6685\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5950 - accuracy: 0.6634 - val_loss: 0.5887 - val_accuracy: 0.6689\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5953 - accuracy: 0.6652 - val_loss: 0.5866 - val_accuracy: 0.6724\n",
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5943 - accuracy: 0.6672 - val_loss: 0.5854 - val_accuracy: 0.6735\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5938 - accuracy: 0.6681 - val_loss: 0.5864 - val_accuracy: 0.6689\n",
      "Epoch 13/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5926 - accuracy: 0.6658 - val_loss: 0.5918 - val_accuracy: 0.6674\n",
      "Epoch 14/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5926 - accuracy: 0.6692 - val_loss: 0.5841 - val_accuracy: 0.6744\n",
      "Epoch 15/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5938 - accuracy: 0.6663 - val_loss: 0.5889 - val_accuracy: 0.6723\n",
      "Epoch 16/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5943 - accuracy: 0.6648 - val_loss: 0.5875 - val_accuracy: 0.6672\n",
      "Epoch 17/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5925 - accuracy: 0.6678 - val_loss: 0.5848 - val_accuracy: 0.6734\n",
      "Epoch 18/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5916 - accuracy: 0.6694 - val_loss: 0.5847 - val_accuracy: 0.6710\n",
      "Epoch 19/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5908 - accuracy: 0.6681 - val_loss: 0.5835 - val_accuracy: 0.6721\n",
      "Epoch 20/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5916 - accuracy: 0.6676 - val_loss: 0.5832 - val_accuracy: 0.6728\n",
      "Epoch 21/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5888 - accuracy: 0.6700 - val_loss: 0.5850 - val_accuracy: 0.6731\n",
      "Epoch 22/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5910 - accuracy: 0.6677 - val_loss: 0.5851 - val_accuracy: 0.6737\n",
      "Epoch 23/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5883 - accuracy: 0.6728 - val_loss: 0.5844 - val_accuracy: 0.6753\n",
      "Epoch 24/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5890 - accuracy: 0.6718 - val_loss: 0.5842 - val_accuracy: 0.6743\n",
      "Epoch 25/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5907 - accuracy: 0.6690 - val_loss: 0.5855 - val_accuracy: 0.6727\n",
      "1735/1735 [==============================] - 1s 424us/step - loss: 0.5883 - accuracy: 0.6669\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 6s 2ms/step - loss: 0.6346 - accuracy: 0.6250 - val_loss: 0.6111 - val_accuracy: 0.6464\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6124 - accuracy: 0.6514 - val_loss: 0.6106 - val_accuracy: 0.6556\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6093 - accuracy: 0.6528 - val_loss: 0.6061 - val_accuracy: 0.6573\n",
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6032 - accuracy: 0.6588 - val_loss: 0.6014 - val_accuracy: 0.6595\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5998 - accuracy: 0.6597 - val_loss: 0.6000 - val_accuracy: 0.6626\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5988 - accuracy: 0.6637 - val_loss: 0.6151 - val_accuracy: 0.6611\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5963 - accuracy: 0.6632 - val_loss: 0.5950 - val_accuracy: 0.6666\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5974 - accuracy: 0.6634 - val_loss: 0.5981 - val_accuracy: 0.6617\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5955 - accuracy: 0.6669 - val_loss: 0.5953 - val_accuracy: 0.6658\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5957 - accuracy: 0.6651 - val_loss: 0.5951 - val_accuracy: 0.6636\n",
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5952 - accuracy: 0.6655 - val_loss: 0.5990 - val_accuracy: 0.6602\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5936 - accuracy: 0.6658 - val_loss: 0.5951 - val_accuracy: 0.6658\n",
      "1735/1735 [==============================] - 1s 432us/step - loss: 0.5907 - accuracy: 0.6698\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 7s 2ms/step - loss: 0.6395 - accuracy: 0.6234 - val_loss: 0.6038 - val_accuracy: 0.6585\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6131 - accuracy: 0.6509 - val_loss: 0.6035 - val_accuracy: 0.6634\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6077 - accuracy: 0.6544 - val_loss: 0.6034 - val_accuracy: 0.6600\n",
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6059 - accuracy: 0.6525 - val_loss: 0.5916 - val_accuracy: 0.6644\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6018 - accuracy: 0.6597 - val_loss: 0.5974 - val_accuracy: 0.6685\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5969 - accuracy: 0.6629 - val_loss: 0.5944 - val_accuracy: 0.6673\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6019 - accuracy: 0.6569 - val_loss: 0.5909 - val_accuracy: 0.6693\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5962 - accuracy: 0.6646 - val_loss: 0.5913 - val_accuracy: 0.6695\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5973 - accuracy: 0.6630 - val_loss: 0.5944 - val_accuracy: 0.6705\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5962 - accuracy: 0.6627 - val_loss: 0.5878 - val_accuracy: 0.6744\n",
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5945 - accuracy: 0.6640 - val_loss: 0.5884 - val_accuracy: 0.6671\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5958 - accuracy: 0.6637 - val_loss: 0.5911 - val_accuracy: 0.6737\n",
      "Epoch 13/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5954 - accuracy: 0.6639 - val_loss: 0.5840 - val_accuracy: 0.6714\n",
      "Epoch 14/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5939 - accuracy: 0.6654 - val_loss: 0.5895 - val_accuracy: 0.6715\n",
      "Epoch 15/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5926 - accuracy: 0.6648 - val_loss: 0.5855 - val_accuracy: 0.6707\n",
      "Epoch 16/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5912 - accuracy: 0.6688 - val_loss: 0.5855 - val_accuracy: 0.6735\n",
      "Epoch 17/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5924 - accuracy: 0.6664 - val_loss: 0.5856 - val_accuracy: 0.6717\n",
      "Epoch 18/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5939 - accuracy: 0.6645 - val_loss: 0.5834 - val_accuracy: 0.6720\n",
      "Epoch 19/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5927 - accuracy: 0.6677 - val_loss: 0.5887 - val_accuracy: 0.6675\n",
      "Epoch 20/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5914 - accuracy: 0.6659 - val_loss: 0.5852 - val_accuracy: 0.6748\n",
      "Epoch 21/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5883 - accuracy: 0.6676 - val_loss: 0.5851 - val_accuracy: 0.6724\n",
      "Epoch 22/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5921 - accuracy: 0.6651 - val_loss: 0.5855 - val_accuracy: 0.6730\n",
      "Epoch 23/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5884 - accuracy: 0.6702 - val_loss: 0.5907 - val_accuracy: 0.6666\n",
      "1735/1735 [==============================] - 1s 459us/step - loss: 0.5893 - accuracy: 0.6709\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 6s 2ms/step - loss: 0.6380 - accuracy: 0.6259 - val_loss: 0.6020 - val_accuracy: 0.6599\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6131 - accuracy: 0.6507 - val_loss: 0.6026 - val_accuracy: 0.6614\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6112 - accuracy: 0.6528 - val_loss: 0.6014 - val_accuracy: 0.6634\n",
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6059 - accuracy: 0.6578 - val_loss: 0.5950 - val_accuracy: 0.6644\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6007 - accuracy: 0.6593 - val_loss: 0.5914 - val_accuracy: 0.6641\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6009 - accuracy: 0.6572 - val_loss: 0.5943 - val_accuracy: 0.6693\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6003 - accuracy: 0.6617 - val_loss: 0.5872 - val_accuracy: 0.6693\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5978 - accuracy: 0.6619 - val_loss: 0.5908 - val_accuracy: 0.6691\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5966 - accuracy: 0.6641 - val_loss: 0.5912 - val_accuracy: 0.6709\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5960 - accuracy: 0.6662 - val_loss: 0.5876 - val_accuracy: 0.6704\n",
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5921 - accuracy: 0.6702 - val_loss: 0.5914 - val_accuracy: 0.6730\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5944 - accuracy: 0.6647 - val_loss: 0.5906 - val_accuracy: 0.6711\n",
      "1735/1735 [==============================] - 1s 457us/step - loss: 0.5906 - accuracy: 0.6659\n",
      "Epoch 1/100\n",
      "3123/3123 [==============================] - 7s 2ms/step - loss: 0.6435 - accuracy: 0.6203 - val_loss: 0.6087 - val_accuracy: 0.6530\n",
      "Epoch 2/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6133 - accuracy: 0.6495 - val_loss: 0.6088 - val_accuracy: 0.6527\n",
      "Epoch 3/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6070 - accuracy: 0.6556 - val_loss: 0.6084 - val_accuracy: 0.6558\n",
      "Epoch 4/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6039 - accuracy: 0.6574 - val_loss: 0.6011 - val_accuracy: 0.6571\n",
      "Epoch 5/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6042 - accuracy: 0.6575 - val_loss: 0.6070 - val_accuracy: 0.6513\n",
      "Epoch 6/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6020 - accuracy: 0.6580 - val_loss: 0.5996 - val_accuracy: 0.6609\n",
      "Epoch 7/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.6004 - accuracy: 0.6585 - val_loss: 0.5990 - val_accuracy: 0.6628\n",
      "Epoch 8/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5977 - accuracy: 0.6628 - val_loss: 0.5990 - val_accuracy: 0.6617\n",
      "Epoch 9/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5985 - accuracy: 0.6602 - val_loss: 0.5993 - val_accuracy: 0.6611\n",
      "Epoch 10/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5978 - accuracy: 0.6623 - val_loss: 0.5981 - val_accuracy: 0.6651\n",
      "Epoch 11/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5952 - accuracy: 0.6642 - val_loss: 0.5987 - val_accuracy: 0.6624\n",
      "Epoch 12/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5953 - accuracy: 0.6654 - val_loss: 0.5968 - val_accuracy: 0.6617\n",
      "Epoch 13/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5958 - accuracy: 0.6636 - val_loss: 0.5969 - val_accuracy: 0.6607\n",
      "Epoch 14/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5950 - accuracy: 0.6646 - val_loss: 0.6019 - val_accuracy: 0.6541\n",
      "Epoch 15/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5919 - accuracy: 0.6702 - val_loss: 0.5957 - val_accuracy: 0.6664\n",
      "Epoch 16/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5950 - accuracy: 0.6632 - val_loss: 0.5990 - val_accuracy: 0.6483\n",
      "Epoch 17/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5943 - accuracy: 0.6670 - val_loss: 0.5947 - val_accuracy: 0.6668\n",
      "Epoch 18/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5922 - accuracy: 0.6674 - val_loss: 0.5958 - val_accuracy: 0.6632\n",
      "Epoch 19/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5950 - accuracy: 0.6666 - val_loss: 0.5964 - val_accuracy: 0.6651\n",
      "Epoch 20/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5939 - accuracy: 0.6645 - val_loss: 0.5994 - val_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5922 - accuracy: 0.6679 - val_loss: 0.5942 - val_accuracy: 0.6651\n",
      "Epoch 22/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5916 - accuracy: 0.6683 - val_loss: 0.5981 - val_accuracy: 0.6655\n",
      "Epoch 23/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5909 - accuracy: 0.6694 - val_loss: 0.5983 - val_accuracy: 0.6657\n",
      "Epoch 24/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5911 - accuracy: 0.6682 - val_loss: 0.5932 - val_accuracy: 0.6675\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5892 - accuracy: 0.6710 - val_loss: 0.5931 - val_accuracy: 0.6640\n",
      "Epoch 26/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5906 - accuracy: 0.6667 - val_loss: 0.5937 - val_accuracy: 0.6635\n",
      "Epoch 27/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5890 - accuracy: 0.6691 - val_loss: 0.5929 - val_accuracy: 0.6658\n",
      "Epoch 28/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5910 - accuracy: 0.6670 - val_loss: 0.5933 - val_accuracy: 0.6662\n",
      "Epoch 29/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5913 - accuracy: 0.6683 - val_loss: 0.5939 - val_accuracy: 0.6675\n",
      "Epoch 30/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5894 - accuracy: 0.6679 - val_loss: 0.5972 - val_accuracy: 0.6670\n",
      "Epoch 31/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5907 - accuracy: 0.6695 - val_loss: 0.5961 - val_accuracy: 0.6686\n",
      "Epoch 32/100\n",
      "3123/3123 [==============================] - 5s 2ms/step - loss: 0.5859 - accuracy: 0.6720 - val_loss: 0.5996 - val_accuracy: 0.6522\n",
      "1735/1735 [==============================] - 1s 458us/step - loss: 0.5868 - accuracy: 0.6709\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 2s 808us/step - loss: 0.6392 - accuracy: 0.6223 - val_loss: 0.5993 - val_accuracy: 0.6617\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 2s 755us/step - loss: 0.6066 - accuracy: 0.6507 - val_loss: 0.5927 - val_accuracy: 0.6688\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 2s 759us/step - loss: 0.5982 - accuracy: 0.6601 - val_loss: 0.5883 - val_accuracy: 0.6662\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 2s 761us/step - loss: 0.5973 - accuracy: 0.6593 - val_loss: 0.5859 - val_accuracy: 0.6704\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 2s 754us/step - loss: 0.5934 - accuracy: 0.6643 - val_loss: 0.5901 - val_accuracy: 0.6635\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 1s 728us/step - loss: 0.5939 - accuracy: 0.6617 - val_loss: 0.5875 - val_accuracy: 0.6710\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 1s 726us/step - loss: 0.5935 - accuracy: 0.6628 - val_loss: 0.5864 - val_accuracy: 0.6725\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 1s 727us/step - loss: 0.5910 - accuracy: 0.6643 - val_loss: 0.5869 - val_accuracy: 0.6680\n",
      "Epoch 9/100\n",
      "1999/1999 [==============================] - 1s 736us/step - loss: 0.5924 - accuracy: 0.6668 - val_loss: 0.5864 - val_accuracy: 0.6721\n",
      "1111/1111 [==============================] - 0s 282us/step - loss: 0.5926 - accuracy: 0.6665\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 2s 815us/step - loss: 0.6278 - accuracy: 0.6334 - val_loss: 0.5999 - val_accuracy: 0.6644\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 2s 782us/step - loss: 0.6046 - accuracy: 0.6553 - val_loss: 0.5916 - val_accuracy: 0.6713\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 2s 776us/step - loss: 0.6001 - accuracy: 0.6592 - val_loss: 0.5910 - val_accuracy: 0.6668\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 2s 782us/step - loss: 0.5970 - accuracy: 0.6613 - val_loss: 0.5897 - val_accuracy: 0.6708\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 2s 769us/step - loss: 0.5949 - accuracy: 0.6643 - val_loss: 0.5885 - val_accuracy: 0.6671\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 2s 763us/step - loss: 0.5940 - accuracy: 0.6648 - val_loss: 0.5909 - val_accuracy: 0.6617\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 1s 738us/step - loss: 0.5923 - accuracy: 0.6682 - val_loss: 0.5868 - val_accuracy: 0.6739\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 2s 755us/step - loss: 0.5929 - accuracy: 0.6650 - val_loss: 0.5859 - val_accuracy: 0.6697\n",
      "Epoch 9/100\n",
      "1999/1999 [==============================] - 1s 741us/step - loss: 0.5924 - accuracy: 0.6646 - val_loss: 0.5879 - val_accuracy: 0.6703\n",
      "Epoch 10/100\n",
      "1999/1999 [==============================] - 1s 746us/step - loss: 0.5937 - accuracy: 0.6651 - val_loss: 0.5852 - val_accuracy: 0.6746\n",
      "Epoch 11/100\n",
      "1999/1999 [==============================] - 2s 754us/step - loss: 0.5925 - accuracy: 0.6663 - val_loss: 0.5845 - val_accuracy: 0.6724\n",
      "Epoch 12/100\n",
      "1999/1999 [==============================] - 1s 744us/step - loss: 0.5897 - accuracy: 0.6689 - val_loss: 0.5865 - val_accuracy: 0.6669\n",
      "Epoch 13/100\n",
      "1999/1999 [==============================] - 2s 752us/step - loss: 0.5896 - accuracy: 0.6696 - val_loss: 0.5858 - val_accuracy: 0.6731\n",
      "Epoch 14/100\n",
      "1999/1999 [==============================] - 2s 758us/step - loss: 0.5915 - accuracy: 0.6656 - val_loss: 0.5855 - val_accuracy: 0.6744\n",
      "Epoch 15/100\n",
      "1999/1999 [==============================] - 1s 750us/step - loss: 0.5893 - accuracy: 0.6693 - val_loss: 0.5842 - val_accuracy: 0.6746\n",
      "Epoch 16/100\n",
      "1999/1999 [==============================] - 2s 786us/step - loss: 0.5897 - accuracy: 0.6675 - val_loss: 0.5860 - val_accuracy: 0.6729\n",
      "Epoch 17/100\n",
      "1999/1999 [==============================] - 2s 764us/step - loss: 0.5881 - accuracy: 0.6695 - val_loss: 0.5840 - val_accuracy: 0.6750\n",
      "Epoch 18/100\n",
      "1999/1999 [==============================] - 2s 757us/step - loss: 0.5869 - accuracy: 0.6725 - val_loss: 0.5861 - val_accuracy: 0.6726\n",
      "Epoch 19/100\n",
      "1999/1999 [==============================] - 2s 764us/step - loss: 0.5917 - accuracy: 0.6665 - val_loss: 0.5881 - val_accuracy: 0.6721\n",
      "Epoch 20/100\n",
      "1999/1999 [==============================] - 2s 755us/step - loss: 0.5872 - accuracy: 0.6696 - val_loss: 0.5838 - val_accuracy: 0.6731\n",
      "Epoch 21/100\n",
      "1999/1999 [==============================] - 1s 750us/step - loss: 0.5876 - accuracy: 0.6707 - val_loss: 0.5839 - val_accuracy: 0.6733\n",
      "Epoch 22/100\n",
      "1999/1999 [==============================] - 2s 766us/step - loss: 0.5873 - accuracy: 0.6705 - val_loss: 0.5849 - val_accuracy: 0.6741\n",
      "Epoch 23/100\n",
      "1999/1999 [==============================] - 2s 759us/step - loss: 0.5894 - accuracy: 0.6698 - val_loss: 0.5845 - val_accuracy: 0.6735\n",
      "Epoch 24/100\n",
      "1999/1999 [==============================] - 2s 753us/step - loss: 0.5865 - accuracy: 0.6740 - val_loss: 0.5859 - val_accuracy: 0.6703\n",
      "Epoch 25/100\n",
      "1999/1999 [==============================] - 2s 768us/step - loss: 0.5864 - accuracy: 0.6709 - val_loss: 0.5857 - val_accuracy: 0.6706\n",
      "1111/1111 [==============================] - 0s 285us/step - loss: 0.5896 - accuracy: 0.6670\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 2s 855us/step - loss: 0.6287 - accuracy: 0.6323 - val_loss: 0.6015 - val_accuracy: 0.6580\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 2s 768us/step - loss: 0.6006 - accuracy: 0.6593 - val_loss: 0.6023 - val_accuracy: 0.6571\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 2s 759us/step - loss: 0.6007 - accuracy: 0.6582 - val_loss: 0.5960 - val_accuracy: 0.6608\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 2s 757us/step - loss: 0.5971 - accuracy: 0.6628 - val_loss: 0.5994 - val_accuracy: 0.6580\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 2s 777us/step - loss: 0.5971 - accuracy: 0.6590 - val_loss: 0.5962 - val_accuracy: 0.6653\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 2s 762us/step - loss: 0.5962 - accuracy: 0.6621 - val_loss: 0.5938 - val_accuracy: 0.6652\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 2s 771us/step - loss: 0.5930 - accuracy: 0.6663 - val_loss: 0.5965 - val_accuracy: 0.6611\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 2s 766us/step - loss: 0.5940 - accuracy: 0.6630 - val_loss: 0.5935 - val_accuracy: 0.6634\n",
      "Epoch 9/100\n",
      "1999/1999 [==============================] - 2s 763us/step - loss: 0.5935 - accuracy: 0.6628 - val_loss: 0.5955 - val_accuracy: 0.6599\n",
      "Epoch 10/100\n",
      "1999/1999 [==============================] - 2s 775us/step - loss: 0.5929 - accuracy: 0.6655 - val_loss: 0.5949 - val_accuracy: 0.6616\n",
      "Epoch 11/100\n",
      "1999/1999 [==============================] - 2s 768us/step - loss: 0.5929 - accuracy: 0.6646 - val_loss: 0.5929 - val_accuracy: 0.6674\n",
      "Epoch 12/100\n",
      "1999/1999 [==============================] - 2s 795us/step - loss: 0.5896 - accuracy: 0.6673 - val_loss: 0.5927 - val_accuracy: 0.6684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "1999/1999 [==============================] - 1s 742us/step - loss: 0.5903 - accuracy: 0.6647 - val_loss: 0.5925 - val_accuracy: 0.6657\n",
      "Epoch 14/100\n",
      "1999/1999 [==============================] - 1s 728us/step - loss: 0.5918 - accuracy: 0.6645 - val_loss: 0.5926 - val_accuracy: 0.6677\n",
      "Epoch 15/100\n",
      "1999/1999 [==============================] - 1s 728us/step - loss: 0.5905 - accuracy: 0.6657 - val_loss: 0.5936 - val_accuracy: 0.6652\n",
      "Epoch 16/100\n",
      "1999/1999 [==============================] - 1s 742us/step - loss: 0.5893 - accuracy: 0.6697 - val_loss: 0.5923 - val_accuracy: 0.6662\n",
      "Epoch 17/100\n",
      "1999/1999 [==============================] - 1s 731us/step - loss: 0.5896 - accuracy: 0.6673 - val_loss: 0.5914 - val_accuracy: 0.6673\n",
      "Epoch 18/100\n",
      "1999/1999 [==============================] - 1s 728us/step - loss: 0.5894 - accuracy: 0.6706 - val_loss: 0.5929 - val_accuracy: 0.6657\n",
      "Epoch 19/100\n",
      "1999/1999 [==============================] - 1s 739us/step - loss: 0.5919 - accuracy: 0.6658 - val_loss: 0.5931 - val_accuracy: 0.6676\n",
      "Epoch 20/100\n",
      "1999/1999 [==============================] - 1s 735us/step - loss: 0.5894 - accuracy: 0.6679 - val_loss: 0.5947 - val_accuracy: 0.6634\n",
      "Epoch 21/100\n",
      "1999/1999 [==============================] - 1s 736us/step - loss: 0.5887 - accuracy: 0.6680 - val_loss: 0.5944 - val_accuracy: 0.6662\n",
      "Epoch 22/100\n",
      "1999/1999 [==============================] - 2s 764us/step - loss: 0.5887 - accuracy: 0.6674 - val_loss: 0.5927 - val_accuracy: 0.6670\n",
      "1111/1111 [==============================] - 0s 277us/step - loss: 0.5880 - accuracy: 0.6706\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 2s 840us/step - loss: 0.6246 - accuracy: 0.6353 - val_loss: 0.5969 - val_accuracy: 0.6647\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 2s 787us/step - loss: 0.6030 - accuracy: 0.6562 - val_loss: 0.5919 - val_accuracy: 0.6693\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 2s 769us/step - loss: 0.5985 - accuracy: 0.6585 - val_loss: 0.5881 - val_accuracy: 0.6694\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 2s 773us/step - loss: 0.5956 - accuracy: 0.6614 - val_loss: 0.5893 - val_accuracy: 0.6680\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 2s 769us/step - loss: 0.5928 - accuracy: 0.6641 - val_loss: 0.5881 - val_accuracy: 0.6685\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 2s 766us/step - loss: 0.5923 - accuracy: 0.6650 - val_loss: 0.5881 - val_accuracy: 0.6707\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 2s 784us/step - loss: 0.5933 - accuracy: 0.6653 - val_loss: 0.5853 - val_accuracy: 0.6690\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 2s 769us/step - loss: 0.5895 - accuracy: 0.6642 - val_loss: 0.5893 - val_accuracy: 0.6652\n",
      "Epoch 9/100\n",
      "1999/1999 [==============================] - 2s 771us/step - loss: 0.5945 - accuracy: 0.6596 - val_loss: 0.5842 - val_accuracy: 0.6717\n",
      "Epoch 10/100\n",
      "1999/1999 [==============================] - 2s 814us/step - loss: 0.5900 - accuracy: 0.6681 - val_loss: 0.5879 - val_accuracy: 0.6711\n",
      "Epoch 11/100\n",
      "1999/1999 [==============================] - 2s 772us/step - loss: 0.5894 - accuracy: 0.6674 - val_loss: 0.5881 - val_accuracy: 0.6681\n",
      "Epoch 12/100\n",
      "1999/1999 [==============================] - 2s 777us/step - loss: 0.5918 - accuracy: 0.6633 - val_loss: 0.5897 - val_accuracy: 0.6655\n",
      "Epoch 13/100\n",
      "1999/1999 [==============================] - 2s 783us/step - loss: 0.5896 - accuracy: 0.6664 - val_loss: 0.5835 - val_accuracy: 0.6738\n",
      "Epoch 14/100\n",
      "1999/1999 [==============================] - 2s 774us/step - loss: 0.5883 - accuracy: 0.6687 - val_loss: 0.5853 - val_accuracy: 0.6716\n",
      "Epoch 15/100\n",
      "1999/1999 [==============================] - 2s 783us/step - loss: 0.5889 - accuracy: 0.6693 - val_loss: 0.5834 - val_accuracy: 0.6738\n",
      "Epoch 16/100\n",
      "1999/1999 [==============================] - 2s 786us/step - loss: 0.5875 - accuracy: 0.6672 - val_loss: 0.5838 - val_accuracy: 0.6730\n",
      "Epoch 17/100\n",
      "1999/1999 [==============================] - 2s 779us/step - loss: 0.5893 - accuracy: 0.6675 - val_loss: 0.5839 - val_accuracy: 0.6713\n",
      "Epoch 18/100\n",
      "1999/1999 [==============================] - 2s 787us/step - loss: 0.5855 - accuracy: 0.6721 - val_loss: 0.5855 - val_accuracy: 0.6752\n",
      "Epoch 19/100\n",
      "1999/1999 [==============================] - 2s 777us/step - loss: 0.5899 - accuracy: 0.6647 - val_loss: 0.5837 - val_accuracy: 0.6739\n",
      "Epoch 20/100\n",
      "1999/1999 [==============================] - 2s 806us/step - loss: 0.5849 - accuracy: 0.6707 - val_loss: 0.5831 - val_accuracy: 0.6752\n",
      "Epoch 21/100\n",
      "1999/1999 [==============================] - 2s 802us/step - loss: 0.5873 - accuracy: 0.6685 - val_loss: 0.5836 - val_accuracy: 0.6737\n",
      "Epoch 22/100\n",
      "1999/1999 [==============================] - 2s 784us/step - loss: 0.5874 - accuracy: 0.6676 - val_loss: 0.5828 - val_accuracy: 0.6744\n",
      "Epoch 23/100\n",
      "1999/1999 [==============================] - 2s 782us/step - loss: 0.5875 - accuracy: 0.6714 - val_loss: 0.5840 - val_accuracy: 0.6719\n",
      "Epoch 24/100\n",
      "1999/1999 [==============================] - 2s 793us/step - loss: 0.5867 - accuracy: 0.6697 - val_loss: 0.5836 - val_accuracy: 0.6744\n",
      "Epoch 25/100\n",
      "1999/1999 [==============================] - 2s 790us/step - loss: 0.5879 - accuracy: 0.6683 - val_loss: 0.5837 - val_accuracy: 0.6720\n",
      "Epoch 26/100\n",
      "1999/1999 [==============================] - 2s 791us/step - loss: 0.5883 - accuracy: 0.6675 - val_loss: 0.5826 - val_accuracy: 0.6725\n",
      "Epoch 27/100\n",
      "1999/1999 [==============================] - 2s 797us/step - loss: 0.5846 - accuracy: 0.6728 - val_loss: 0.5849 - val_accuracy: 0.6720\n",
      "Epoch 28/100\n",
      "1999/1999 [==============================] - 2s 785us/step - loss: 0.5855 - accuracy: 0.6721 - val_loss: 0.5840 - val_accuracy: 0.6697\n",
      "Epoch 29/100\n",
      "1999/1999 [==============================] - 2s 795us/step - loss: 0.5865 - accuracy: 0.6707 - val_loss: 0.5829 - val_accuracy: 0.6763\n",
      "Epoch 30/100\n",
      "1999/1999 [==============================] - 2s 818us/step - loss: 0.5843 - accuracy: 0.6708 - val_loss: 0.5856 - val_accuracy: 0.6715\n",
      "Epoch 31/100\n",
      "1999/1999 [==============================] - 2s 787us/step - loss: 0.5846 - accuracy: 0.6699 - val_loss: 0.5843 - val_accuracy: 0.6716\n",
      "1111/1111 [==============================] - 0s 309us/step - loss: 0.5886 - accuracy: 0.6709\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 2s 848us/step - loss: 0.6363 - accuracy: 0.6284 - val_loss: 0.6019 - val_accuracy: 0.6605\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 2s 791us/step - loss: 0.6061 - accuracy: 0.6528 - val_loss: 0.5925 - val_accuracy: 0.6688\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 2s 803us/step - loss: 0.6009 - accuracy: 0.6600 - val_loss: 0.5920 - val_accuracy: 0.6631\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 2s 790us/step - loss: 0.5973 - accuracy: 0.6622 - val_loss: 0.5882 - val_accuracy: 0.6738\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 2s 798us/step - loss: 0.5955 - accuracy: 0.6635 - val_loss: 0.5874 - val_accuracy: 0.6697\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 2s 795us/step - loss: 0.5953 - accuracy: 0.6626 - val_loss: 0.5863 - val_accuracy: 0.6689\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 2s 812us/step - loss: 0.5917 - accuracy: 0.6654 - val_loss: 0.5865 - val_accuracy: 0.6694\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 2s 808us/step - loss: 0.5932 - accuracy: 0.6657 - val_loss: 0.5839 - val_accuracy: 0.6741\n",
      "Epoch 9/100\n",
      "1999/1999 [==============================] - 2s 829us/step - loss: 0.5939 - accuracy: 0.6646 - val_loss: 0.5852 - val_accuracy: 0.6669\n",
      "Epoch 10/100\n",
      "1999/1999 [==============================] - 2s 806us/step - loss: 0.5908 - accuracy: 0.6675 - val_loss: 0.5833 - val_accuracy: 0.6735\n",
      "Epoch 11/100\n",
      "1999/1999 [==============================] - 2s 810us/step - loss: 0.5923 - accuracy: 0.6631 - val_loss: 0.5889 - val_accuracy: 0.6684\n",
      "Epoch 12/100\n",
      "1999/1999 [==============================] - 2s 796us/step - loss: 0.5906 - accuracy: 0.6680 - val_loss: 0.5848 - val_accuracy: 0.6695\n",
      "Epoch 13/100\n",
      "1999/1999 [==============================] - 2s 805us/step - loss: 0.5907 - accuracy: 0.6670 - val_loss: 0.5827 - val_accuracy: 0.6748\n",
      "Epoch 14/100\n",
      "1999/1999 [==============================] - 2s 763us/step - loss: 0.5910 - accuracy: 0.6691 - val_loss: 0.5847 - val_accuracy: 0.6749\n",
      "Epoch 15/100\n",
      "1999/1999 [==============================] - 2s 758us/step - loss: 0.5908 - accuracy: 0.6682 - val_loss: 0.5827 - val_accuracy: 0.6733\n",
      "Epoch 16/100\n",
      "1999/1999 [==============================] - 2s 769us/step - loss: 0.5918 - accuracy: 0.6679 - val_loss: 0.5837 - val_accuracy: 0.6717\n",
      "Epoch 17/100\n",
      "1999/1999 [==============================] - 2s 758us/step - loss: 0.5898 - accuracy: 0.6669 - val_loss: 0.5822 - val_accuracy: 0.6752\n",
      "Epoch 18/100\n",
      "1999/1999 [==============================] - 2s 759us/step - loss: 0.5896 - accuracy: 0.6686 - val_loss: 0.5841 - val_accuracy: 0.6758\n",
      "Epoch 19/100\n",
      "1999/1999 [==============================] - 2s 792us/step - loss: 0.5888 - accuracy: 0.6697 - val_loss: 0.5841 - val_accuracy: 0.6748\n",
      "Epoch 20/100\n",
      "1999/1999 [==============================] - 2s 763us/step - loss: 0.5895 - accuracy: 0.6679 - val_loss: 0.5831 - val_accuracy: 0.6744\n",
      "Epoch 21/100\n",
      "1999/1999 [==============================] - 2s 763us/step - loss: 0.5883 - accuracy: 0.6718 - val_loss: 0.5841 - val_accuracy: 0.6717\n",
      "Epoch 22/100\n",
      "1999/1999 [==============================] - 2s 768us/step - loss: 0.5887 - accuracy: 0.6691 - val_loss: 0.5841 - val_accuracy: 0.6751\n",
      "1111/1111 [==============================] - 0s 303us/step - loss: 0.5885 - accuracy: 0.6669\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 2s 843us/step - loss: 0.6296 - accuracy: 0.6352 - val_loss: 0.6028 - val_accuracy: 0.6589\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 2s 794us/step - loss: 0.6007 - accuracy: 0.6608 - val_loss: 0.5980 - val_accuracy: 0.6586\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 2s 798us/step - loss: 0.5978 - accuracy: 0.6603 - val_loss: 0.5965 - val_accuracy: 0.6617\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 2s 797us/step - loss: 0.5975 - accuracy: 0.6613 - val_loss: 0.5957 - val_accuracy: 0.6629\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 2s 774us/step - loss: 0.5955 - accuracy: 0.6640 - val_loss: 0.5979 - val_accuracy: 0.6621\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 2s 772us/step - loss: 0.5923 - accuracy: 0.6646 - val_loss: 0.5929 - val_accuracy: 0.6676\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 2s 799us/step - loss: 0.5926 - accuracy: 0.6662 - val_loss: 0.5961 - val_accuracy: 0.6588\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 2s 771us/step - loss: 0.5930 - accuracy: 0.6640 - val_loss: 0.5924 - val_accuracy: 0.6658\n",
      "Epoch 9/100\n",
      "1999/1999 [==============================] - 2s 773us/step - loss: 0.5905 - accuracy: 0.6680 - val_loss: 0.5925 - val_accuracy: 0.6639\n",
      "Epoch 10/100\n",
      "1999/1999 [==============================] - 2s 778us/step - loss: 0.5915 - accuracy: 0.6656 - val_loss: 0.5922 - val_accuracy: 0.6669\n",
      "Epoch 11/100\n",
      "1999/1999 [==============================] - 2s 780us/step - loss: 0.5907 - accuracy: 0.6670 - val_loss: 0.5924 - val_accuracy: 0.6658\n",
      "Epoch 12/100\n",
      "1999/1999 [==============================] - 2s 794us/step - loss: 0.5908 - accuracy: 0.6639 - val_loss: 0.5908 - val_accuracy: 0.6690\n",
      "Epoch 13/100\n",
      "1999/1999 [==============================] - 2s 810us/step - loss: 0.5891 - accuracy: 0.6666 - val_loss: 0.5916 - val_accuracy: 0.6647\n",
      "Epoch 14/100\n",
      "1999/1999 [==============================] - 2s 777us/step - loss: 0.5871 - accuracy: 0.6706 - val_loss: 0.5936 - val_accuracy: 0.6646\n",
      "Epoch 15/100\n",
      "1999/1999 [==============================] - 2s 778us/step - loss: 0.5906 - accuracy: 0.6682 - val_loss: 0.5925 - val_accuracy: 0.6657\n",
      "Epoch 16/100\n",
      "1999/1999 [==============================] - 2s 795us/step - loss: 0.5879 - accuracy: 0.6702 - val_loss: 0.5918 - val_accuracy: 0.6664\n",
      "Epoch 17/100\n",
      "1999/1999 [==============================] - 2s 810us/step - loss: 0.5867 - accuracy: 0.6700 - val_loss: 0.5962 - val_accuracy: 0.6609\n",
      "1111/1111 [==============================] - 0s 304us/step - loss: 0.5870 - accuracy: 0.6695\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 4s 1ms/step - loss: 0.6289 - accuracy: 0.6302 - val_loss: 0.5963 - val_accuracy: 0.6645\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.6053 - accuracy: 0.6549 - val_loss: 0.5943 - val_accuracy: 0.6666\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5986 - accuracy: 0.6607 - val_loss: 0.5889 - val_accuracy: 0.6704\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5972 - accuracy: 0.6617 - val_loss: 0.5876 - val_accuracy: 0.6717\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5983 - accuracy: 0.6596 - val_loss: 0.5873 - val_accuracy: 0.6700\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5944 - accuracy: 0.6638 - val_loss: 0.5895 - val_accuracy: 0.6708\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5959 - accuracy: 0.6628 - val_loss: 0.5855 - val_accuracy: 0.6752\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.6647 - val_loss: 0.5880 - val_accuracy: 0.6716\n",
      "Epoch 9/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5920 - accuracy: 0.6668 - val_loss: 0.5875 - val_accuracy: 0.6725\n",
      "Epoch 10/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5900 - accuracy: 0.6680 - val_loss: 0.5849 - val_accuracy: 0.6718\n",
      "Epoch 11/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5908 - accuracy: 0.6665 - val_loss: 0.5844 - val_accuracy: 0.6735\n",
      "Epoch 12/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5892 - accuracy: 0.6685 - val_loss: 0.5871 - val_accuracy: 0.6717\n",
      "Epoch 13/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5915 - accuracy: 0.6650 - val_loss: 0.5860 - val_accuracy: 0.6717\n",
      "Epoch 14/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5912 - accuracy: 0.6652 - val_loss: 0.5848 - val_accuracy: 0.6726\n",
      "Epoch 15/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5910 - accuracy: 0.6680 - val_loss: 0.5827 - val_accuracy: 0.6742\n",
      "Epoch 16/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5887 - accuracy: 0.6676 - val_loss: 0.5833 - val_accuracy: 0.6721\n",
      "Epoch 17/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5890 - accuracy: 0.6667 - val_loss: 0.5836 - val_accuracy: 0.6770\n",
      "Epoch 18/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5883 - accuracy: 0.6693 - val_loss: 0.5841 - val_accuracy: 0.6726\n",
      "Epoch 19/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5889 - accuracy: 0.6680 - val_loss: 0.5833 - val_accuracy: 0.6744\n",
      "Epoch 20/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5862 - accuracy: 0.6700 - val_loss: 0.5829 - val_accuracy: 0.6744\n",
      "1111/1111 [==============================] - 0s 375us/step - loss: 0.5900 - accuracy: 0.6695\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.6341 - accuracy: 0.6316 - val_loss: 0.6002 - val_accuracy: 0.6618\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.6060 - accuracy: 0.6566 - val_loss: 0.5946 - val_accuracy: 0.6661\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.6012 - accuracy: 0.6615 - val_loss: 0.5904 - val_accuracy: 0.6652\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5979 - accuracy: 0.6603 - val_loss: 0.5863 - val_accuracy: 0.6717\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5950 - accuracy: 0.6645 - val_loss: 0.5890 - val_accuracy: 0.6704\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5954 - accuracy: 0.6654 - val_loss: 0.5882 - val_accuracy: 0.6718\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5930 - accuracy: 0.6677 - val_loss: 0.5860 - val_accuracy: 0.6742\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5934 - accuracy: 0.6668 - val_loss: 0.5875 - val_accuracy: 0.6712\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5929 - accuracy: 0.6656 - val_loss: 0.5862 - val_accuracy: 0.6721\n",
      "Epoch 10/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5920 - accuracy: 0.6671 - val_loss: 0.5841 - val_accuracy: 0.6745\n",
      "Epoch 11/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5919 - accuracy: 0.6669 - val_loss: 0.5832 - val_accuracy: 0.6744\n",
      "Epoch 12/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5923 - accuracy: 0.6667 - val_loss: 0.5833 - val_accuracy: 0.6718\n",
      "Epoch 13/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5904 - accuracy: 0.6702 - val_loss: 0.5855 - val_accuracy: 0.6755\n",
      "Epoch 14/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5902 - accuracy: 0.6672 - val_loss: 0.5874 - val_accuracy: 0.6688\n",
      "Epoch 15/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5901 - accuracy: 0.6677 - val_loss: 0.5849 - val_accuracy: 0.6741\n",
      "Epoch 16/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5895 - accuracy: 0.6670 - val_loss: 0.5852 - val_accuracy: 0.6754\n",
      "1111/1111 [==============================] - 0s 366us/step - loss: 0.5892 - accuracy: 0.6667\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.6365 - accuracy: 0.6197 - val_loss: 0.6089 - val_accuracy: 0.6527\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.6101 - accuracy: 0.6537 - val_loss: 0.6065 - val_accuracy: 0.6544\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.6058 - accuracy: 0.6539 - val_loss: 0.6006 - val_accuracy: 0.6600\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.6018 - accuracy: 0.6590 - val_loss: 0.5992 - val_accuracy: 0.6609\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5973 - accuracy: 0.6599 - val_loss: 0.5968 - val_accuracy: 0.6600\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5967 - accuracy: 0.6602 - val_loss: 0.5962 - val_accuracy: 0.6600\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5927 - accuracy: 0.6671 - val_loss: 0.5971 - val_accuracy: 0.6549\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5956 - accuracy: 0.6637 - val_loss: 0.5940 - val_accuracy: 0.6645\n",
      "Epoch 9/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5943 - accuracy: 0.6656 - val_loss: 0.5934 - val_accuracy: 0.6671\n",
      "Epoch 10/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5946 - accuracy: 0.6630 - val_loss: 0.5945 - val_accuracy: 0.6631\n",
      "Epoch 11/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5927 - accuracy: 0.6671 - val_loss: 0.5919 - val_accuracy: 0.6680\n",
      "Epoch 12/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5949 - accuracy: 0.6640 - val_loss: 0.5936 - val_accuracy: 0.6670\n",
      "Epoch 13/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5912 - accuracy: 0.6670 - val_loss: 0.5936 - val_accuracy: 0.6626\n",
      "Epoch 14/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5907 - accuracy: 0.6676 - val_loss: 0.5926 - val_accuracy: 0.6675\n",
      "Epoch 15/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5906 - accuracy: 0.6666 - val_loss: 0.5945 - val_accuracy: 0.6658\n",
      "Epoch 16/100\n",
      "1999/1999 [==============================] - 2s 1ms/step - loss: 0.5930 - accuracy: 0.6664 - val_loss: 0.5933 - val_accuracy: 0.6629\n",
      "1111/1111 [==============================] - 0s 370us/step - loss: 0.5881 - accuracy: 0.6699\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 4s 1ms/step - loss: 0.6335 - accuracy: 0.6307 - val_loss: 0.6131 - val_accuracy: 0.6536\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.6124 - accuracy: 0.6481 - val_loss: 0.5977 - val_accuracy: 0.6644\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.6023 - accuracy: 0.6566 - val_loss: 0.5958 - val_accuracy: 0.6660\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.6018 - accuracy: 0.6561 - val_loss: 0.5959 - val_accuracy: 0.6678\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.6004 - accuracy: 0.6594 - val_loss: 0.5910 - val_accuracy: 0.6644\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5948 - accuracy: 0.6637 - val_loss: 0.5879 - val_accuracy: 0.6712\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5972 - accuracy: 0.6599 - val_loss: 0.5866 - val_accuracy: 0.6729\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5936 - accuracy: 0.6652 - val_loss: 0.5864 - val_accuracy: 0.6719\n",
      "Epoch 9/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5923 - accuracy: 0.6670 - val_loss: 0.5882 - val_accuracy: 0.6707\n",
      "Epoch 10/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5918 - accuracy: 0.6666 - val_loss: 0.5855 - val_accuracy: 0.6718\n",
      "Epoch 11/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5899 - accuracy: 0.6679 - val_loss: 0.5866 - val_accuracy: 0.6636\n",
      "Epoch 12/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5894 - accuracy: 0.6688 - val_loss: 0.5852 - val_accuracy: 0.6730\n",
      "Epoch 13/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5878 - accuracy: 0.6688 - val_loss: 0.5854 - val_accuracy: 0.6712\n",
      "Epoch 14/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5911 - accuracy: 0.6654 - val_loss: 0.5869 - val_accuracy: 0.6726\n",
      "Epoch 15/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5896 - accuracy: 0.6673 - val_loss: 0.5843 - val_accuracy: 0.6726\n",
      "Epoch 16/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5891 - accuracy: 0.6672 - val_loss: 0.5850 - val_accuracy: 0.6712\n",
      "Epoch 17/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5899 - accuracy: 0.6673 - val_loss: 0.5853 - val_accuracy: 0.6718\n",
      "Epoch 18/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5897 - accuracy: 0.6664 - val_loss: 0.5835 - val_accuracy: 0.6706\n",
      "Epoch 19/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5864 - accuracy: 0.6696 - val_loss: 0.5867 - val_accuracy: 0.6721\n",
      "Epoch 20/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5883 - accuracy: 0.6682 - val_loss: 0.5833 - val_accuracy: 0.6726\n",
      "Epoch 21/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5868 - accuracy: 0.6700 - val_loss: 0.5846 - val_accuracy: 0.6708\n",
      "Epoch 22/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5883 - accuracy: 0.6651 - val_loss: 0.5841 - val_accuracy: 0.6737\n",
      "Epoch 23/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5864 - accuracy: 0.6658 - val_loss: 0.5867 - val_accuracy: 0.6734\n",
      "Epoch 24/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5883 - accuracy: 0.6676 - val_loss: 0.5859 - val_accuracy: 0.6740\n",
      "Epoch 25/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5850 - accuracy: 0.6707 - val_loss: 0.5875 - val_accuracy: 0.6722\n",
      "1111/1111 [==============================] - 0s 411us/step - loss: 0.5901 - accuracy: 0.6707\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 4s 1ms/step - loss: 0.6329 - accuracy: 0.6343 - val_loss: 0.6032 - val_accuracy: 0.6620\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.6068 - accuracy: 0.6557 - val_loss: 0.5952 - val_accuracy: 0.6627\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.6041 - accuracy: 0.6563 - val_loss: 0.5917 - val_accuracy: 0.6689\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5991 - accuracy: 0.6617 - val_loss: 0.5907 - val_accuracy: 0.6698\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5976 - accuracy: 0.6631 - val_loss: 0.5882 - val_accuracy: 0.6714\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5954 - accuracy: 0.6676 - val_loss: 0.5847 - val_accuracy: 0.6726\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5930 - accuracy: 0.6663 - val_loss: 0.5869 - val_accuracy: 0.6664\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5941 - accuracy: 0.6658 - val_loss: 0.5855 - val_accuracy: 0.6732\n",
      "Epoch 9/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5931 - accuracy: 0.6656 - val_loss: 0.5862 - val_accuracy: 0.6715\n",
      "Epoch 10/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5924 - accuracy: 0.6664 - val_loss: 0.5861 - val_accuracy: 0.6721\n",
      "Epoch 11/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5899 - accuracy: 0.6697 - val_loss: 0.5872 - val_accuracy: 0.6718\n",
      "1111/1111 [==============================] - 0s 402us/step - loss: 0.5910 - accuracy: 0.6661\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.6320 - accuracy: 0.6288 - val_loss: 0.6093 - val_accuracy: 0.6519\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.6060 - accuracy: 0.6538 - val_loss: 0.6015 - val_accuracy: 0.6628\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.6040 - accuracy: 0.6550 - val_loss: 0.6031 - val_accuracy: 0.6614\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5991 - accuracy: 0.6601 - val_loss: 0.5991 - val_accuracy: 0.6589\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5966 - accuracy: 0.6623 - val_loss: 0.5969 - val_accuracy: 0.6625\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5972 - accuracy: 0.6614 - val_loss: 0.5951 - val_accuracy: 0.6645\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5940 - accuracy: 0.6631 - val_loss: 0.5963 - val_accuracy: 0.6626\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5933 - accuracy: 0.6660 - val_loss: 0.5938 - val_accuracy: 0.6664\n",
      "Epoch 9/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5944 - accuracy: 0.6649 - val_loss: 0.5969 - val_accuracy: 0.6605\n",
      "Epoch 10/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5941 - accuracy: 0.6644 - val_loss: 0.5949 - val_accuracy: 0.6662\n",
      "Epoch 11/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5932 - accuracy: 0.6657 - val_loss: 0.5943 - val_accuracy: 0.6657\n",
      "Epoch 12/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5904 - accuracy: 0.6660 - val_loss: 0.5960 - val_accuracy: 0.6627\n",
      "Epoch 13/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5881 - accuracy: 0.6705 - val_loss: 0.5933 - val_accuracy: 0.6644\n",
      "Epoch 14/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5924 - accuracy: 0.6633 - val_loss: 0.5953 - val_accuracy: 0.6622\n",
      "Epoch 15/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5909 - accuracy: 0.6671 - val_loss: 0.5929 - val_accuracy: 0.6660\n",
      "Epoch 16/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5914 - accuracy: 0.6643 - val_loss: 0.5937 - val_accuracy: 0.6671\n",
      "Epoch 17/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5893 - accuracy: 0.6679 - val_loss: 0.5929 - val_accuracy: 0.6670\n",
      "Epoch 18/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5878 - accuracy: 0.6733 - val_loss: 0.5937 - val_accuracy: 0.6654\n",
      "Epoch 19/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5898 - accuracy: 0.6686 - val_loss: 0.5919 - val_accuracy: 0.6668\n",
      "Epoch 20/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5867 - accuracy: 0.6707 - val_loss: 0.5951 - val_accuracy: 0.6641\n",
      "Epoch 21/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5884 - accuracy: 0.6701 - val_loss: 0.5957 - val_accuracy: 0.6665\n",
      "Epoch 22/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5882 - accuracy: 0.6718 - val_loss: 0.5967 - val_accuracy: 0.6637\n",
      "Epoch 23/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5887 - accuracy: 0.6704 - val_loss: 0.5917 - val_accuracy: 0.6662\n",
      "Epoch 24/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5880 - accuracy: 0.6704 - val_loss: 0.5934 - val_accuracy: 0.6661\n",
      "Epoch 25/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5883 - accuracy: 0.6680 - val_loss: 0.5940 - val_accuracy: 0.6626\n",
      "Epoch 26/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5855 - accuracy: 0.6700 - val_loss: 0.5915 - val_accuracy: 0.6676\n",
      "Epoch 27/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5854 - accuracy: 0.6730 - val_loss: 0.5937 - val_accuracy: 0.6652\n",
      "Epoch 28/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5879 - accuracy: 0.6668 - val_loss: 0.5913 - val_accuracy: 0.6676\n",
      "Epoch 29/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5844 - accuracy: 0.6733 - val_loss: 0.5920 - val_accuracy: 0.6679\n",
      "Epoch 30/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5868 - accuracy: 0.6718 - val_loss: 0.5939 - val_accuracy: 0.6636\n",
      "Epoch 31/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5858 - accuracy: 0.6698 - val_loss: 0.5927 - val_accuracy: 0.6657\n",
      "Epoch 32/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5856 - accuracy: 0.6695 - val_loss: 0.5930 - val_accuracy: 0.6647\n",
      "Epoch 33/100\n",
      "1999/1999 [==============================] - 3s 1ms/step - loss: 0.5857 - accuracy: 0.6711 - val_loss: 0.5925 - val_accuracy: 0.6664\n",
      "1111/1111 [==============================] - 0s 422us/step - loss: 0.5871 - accuracy: 0.6708\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 5s 2ms/step - loss: 0.6437 - accuracy: 0.6175 - val_loss: 0.6031 - val_accuracy: 0.6611\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.6094 - accuracy: 0.6531 - val_loss: 0.6022 - val_accuracy: 0.6608\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.6063 - accuracy: 0.6549 - val_loss: 0.5930 - val_accuracy: 0.6671\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.6022 - accuracy: 0.6567 - val_loss: 0.5921 - val_accuracy: 0.6669\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.6007 - accuracy: 0.6580 - val_loss: 0.5887 - val_accuracy: 0.6698\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5965 - accuracy: 0.6628 - val_loss: 0.5861 - val_accuracy: 0.6706\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5960 - accuracy: 0.6637 - val_loss: 0.5900 - val_accuracy: 0.6663\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5955 - accuracy: 0.6608 - val_loss: 0.5865 - val_accuracy: 0.6726\n",
      "Epoch 9/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5919 - accuracy: 0.6667 - val_loss: 0.5892 - val_accuracy: 0.6708\n",
      "Epoch 10/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5944 - accuracy: 0.6623 - val_loss: 0.5882 - val_accuracy: 0.6653\n",
      "Epoch 11/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5939 - accuracy: 0.6634 - val_loss: 0.5854 - val_accuracy: 0.6678\n",
      "Epoch 12/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5925 - accuracy: 0.6661 - val_loss: 0.5875 - val_accuracy: 0.6680\n",
      "Epoch 13/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5909 - accuracy: 0.6675 - val_loss: 0.5844 - val_accuracy: 0.6720\n",
      "Epoch 14/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5932 - accuracy: 0.6635 - val_loss: 0.5863 - val_accuracy: 0.6715\n",
      "Epoch 15/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5921 - accuracy: 0.6652 - val_loss: 0.5873 - val_accuracy: 0.6718\n",
      "Epoch 16/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5913 - accuracy: 0.6661 - val_loss: 0.5834 - val_accuracy: 0.6734\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5916 - accuracy: 0.6651 - val_loss: 0.5895 - val_accuracy: 0.6726\n",
      "Epoch 18/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5906 - accuracy: 0.6664 - val_loss: 0.5854 - val_accuracy: 0.6735\n",
      "Epoch 19/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5886 - accuracy: 0.6690 - val_loss: 0.5846 - val_accuracy: 0.6741\n",
      "Epoch 20/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5897 - accuracy: 0.6662 - val_loss: 0.5855 - val_accuracy: 0.6724\n",
      "Epoch 21/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5880 - accuracy: 0.6701 - val_loss: 0.5844 - val_accuracy: 0.6737\n",
      "1111/1111 [==============================] - 1s 462us/step - loss: 0.5891 - accuracy: 0.6699\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 5s 2ms/step - loss: 0.6394 - accuracy: 0.6265 - val_loss: 0.5980 - val_accuracy: 0.6617\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.6064 - accuracy: 0.6562 - val_loss: 0.5939 - val_accuracy: 0.6671\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.6053 - accuracy: 0.6577 - val_loss: 0.5913 - val_accuracy: 0.6692\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5999 - accuracy: 0.6612 - val_loss: 0.5883 - val_accuracy: 0.6653\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5986 - accuracy: 0.6618 - val_loss: 0.5873 - val_accuracy: 0.6709\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5979 - accuracy: 0.6639 - val_loss: 0.5928 - val_accuracy: 0.6576\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5954 - accuracy: 0.6678 - val_loss: 0.6026 - val_accuracy: 0.6490\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5973 - accuracy: 0.6606 - val_loss: 0.5870 - val_accuracy: 0.6696\n",
      "Epoch 9/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5944 - accuracy: 0.6655 - val_loss: 0.5915 - val_accuracy: 0.6662\n",
      "Epoch 10/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5932 - accuracy: 0.6656 - val_loss: 0.5855 - val_accuracy: 0.6708\n",
      "Epoch 11/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5935 - accuracy: 0.6660 - val_loss: 0.5846 - val_accuracy: 0.6724\n",
      "Epoch 12/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5961 - accuracy: 0.6628 - val_loss: 0.5868 - val_accuracy: 0.6703\n",
      "Epoch 13/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5949 - accuracy: 0.6654 - val_loss: 0.5859 - val_accuracy: 0.6729\n",
      "Epoch 14/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5916 - accuracy: 0.6670 - val_loss: 0.5850 - val_accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5896 - accuracy: 0.6709 - val_loss: 0.5882 - val_accuracy: 0.6726\n",
      "Epoch 16/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5914 - accuracy: 0.6680 - val_loss: 0.5840 - val_accuracy: 0.6741\n",
      "Epoch 17/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5909 - accuracy: 0.6678 - val_loss: 0.5842 - val_accuracy: 0.6734\n",
      "Epoch 18/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5894 - accuracy: 0.6673 - val_loss: 0.5840 - val_accuracy: 0.6741\n",
      "Epoch 19/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5900 - accuracy: 0.6690 - val_loss: 0.5849 - val_accuracy: 0.6742\n",
      "Epoch 20/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5896 - accuracy: 0.6676 - val_loss: 0.5873 - val_accuracy: 0.6731\n",
      "Epoch 21/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5890 - accuracy: 0.6703 - val_loss: 0.5879 - val_accuracy: 0.6734\n",
      "1111/1111 [==============================] - 1s 467us/step - loss: 0.5897 - accuracy: 0.6663\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 5s 2ms/step - loss: 0.6423 - accuracy: 0.6155 - val_loss: 0.6131 - val_accuracy: 0.6535\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.6093 - accuracy: 0.6536 - val_loss: 0.6098 - val_accuracy: 0.6412\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.6074 - accuracy: 0.6540 - val_loss: 0.6009 - val_accuracy: 0.6603\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.6026 - accuracy: 0.6580 - val_loss: 0.5999 - val_accuracy: 0.6581\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5979 - accuracy: 0.6627 - val_loss: 0.5974 - val_accuracy: 0.6626\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5974 - accuracy: 0.6631 - val_loss: 0.5973 - val_accuracy: 0.6637\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5987 - accuracy: 0.6622 - val_loss: 0.5991 - val_accuracy: 0.6619\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5952 - accuracy: 0.6649 - val_loss: 0.5988 - val_accuracy: 0.6623\n",
      "Epoch 9/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5937 - accuracy: 0.6655 - val_loss: 0.5963 - val_accuracy: 0.6613\n",
      "Epoch 10/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5974 - accuracy: 0.6653 - val_loss: 0.5942 - val_accuracy: 0.6607\n",
      "Epoch 11/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5910 - accuracy: 0.6659 - val_loss: 0.5935 - val_accuracy: 0.6638\n",
      "Epoch 12/100\n",
      "1999/1999 [==============================] - 5s 2ms/step - loss: 0.5925 - accuracy: 0.6661 - val_loss: 0.5944 - val_accuracy: 0.6619\n",
      "Epoch 13/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5907 - accuracy: 0.6647 - val_loss: 0.5942 - val_accuracy: 0.6600\n",
      "Epoch 14/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5907 - accuracy: 0.6695 - val_loss: 0.5938 - val_accuracy: 0.6642\n",
      "Epoch 15/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5905 - accuracy: 0.6674 - val_loss: 0.5932 - val_accuracy: 0.6663\n",
      "Epoch 16/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5895 - accuracy: 0.6700 - val_loss: 0.5920 - val_accuracy: 0.6661\n",
      "Epoch 17/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5931 - accuracy: 0.6663 - val_loss: 0.5934 - val_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5889 - accuracy: 0.6685 - val_loss: 0.5928 - val_accuracy: 0.6659\n",
      "Epoch 19/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5897 - accuracy: 0.6682 - val_loss: 0.5957 - val_accuracy: 0.6640\n",
      "Epoch 20/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5896 - accuracy: 0.6698 - val_loss: 0.5970 - val_accuracy: 0.6562\n",
      "Epoch 21/100\n",
      "1999/1999 [==============================] - 3s 2ms/step - loss: 0.5889 - accuracy: 0.6681 - val_loss: 0.5947 - val_accuracy: 0.6677\n",
      "1111/1111 [==============================] - 1s 454us/step - loss: 0.5881 - accuracy: 0.6684\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 5s 2ms/step - loss: 0.6424 - accuracy: 0.6220 - val_loss: 0.6067 - val_accuracy: 0.6547\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.6079 - accuracy: 0.6561 - val_loss: 0.6000 - val_accuracy: 0.6615\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.6038 - accuracy: 0.6557 - val_loss: 0.6009 - val_accuracy: 0.6662\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.6023 - accuracy: 0.6570 - val_loss: 0.6075 - val_accuracy: 0.6589\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5973 - accuracy: 0.6619 - val_loss: 0.5986 - val_accuracy: 0.6592\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5978 - accuracy: 0.6574 - val_loss: 0.5898 - val_accuracy: 0.6719\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5947 - accuracy: 0.6642 - val_loss: 0.5908 - val_accuracy: 0.6689\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5975 - accuracy: 0.6591 - val_loss: 0.5920 - val_accuracy: 0.6729\n",
      "Epoch 9/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5929 - accuracy: 0.6660 - val_loss: 0.5920 - val_accuracy: 0.6694\n",
      "Epoch 10/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5919 - accuracy: 0.6681 - val_loss: 0.5887 - val_accuracy: 0.6516\n",
      "Epoch 11/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5896 - accuracy: 0.6672 - val_loss: 0.5940 - val_accuracy: 0.6765\n",
      "Epoch 12/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5933 - accuracy: 0.6668 - val_loss: 0.5874 - val_accuracy: 0.6704\n",
      "Epoch 13/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5911 - accuracy: 0.6668 - val_loss: 0.5848 - val_accuracy: 0.6744\n",
      "Epoch 14/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5904 - accuracy: 0.6687 - val_loss: 0.5870 - val_accuracy: 0.6723\n",
      "Epoch 15/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5895 - accuracy: 0.6696 - val_loss: 0.5853 - val_accuracy: 0.6717\n",
      "Epoch 16/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5921 - accuracy: 0.6663 - val_loss: 0.5856 - val_accuracy: 0.6736\n",
      "Epoch 17/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5876 - accuracy: 0.6690 - val_loss: 0.5893 - val_accuracy: 0.6754\n",
      "Epoch 18/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5876 - accuracy: 0.6698 - val_loss: 0.5847 - val_accuracy: 0.6735\n",
      "Epoch 19/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5876 - accuracy: 0.6703 - val_loss: 0.5841 - val_accuracy: 0.6740\n",
      "Epoch 20/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5861 - accuracy: 0.6713 - val_loss: 0.5847 - val_accuracy: 0.6753\n",
      "Epoch 21/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5896 - accuracy: 0.6673 - val_loss: 0.5872 - val_accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5885 - accuracy: 0.6670 - val_loss: 0.5864 - val_accuracy: 0.6729\n",
      "Epoch 23/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5881 - accuracy: 0.6687 - val_loss: 0.5864 - val_accuracy: 0.6746\n",
      "Epoch 24/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5878 - accuracy: 0.6678 - val_loss: 0.5872 - val_accuracy: 0.6727\n",
      "1111/1111 [==============================] - 1s 512us/step - loss: 0.5896 - accuracy: 0.6707\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 5s 2ms/step - loss: 0.6400 - accuracy: 0.6199 - val_loss: 0.5988 - val_accuracy: 0.6619\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.6108 - accuracy: 0.6544 - val_loss: 0.6072 - val_accuracy: 0.6639\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.6033 - accuracy: 0.6604 - val_loss: 0.6005 - val_accuracy: 0.6553\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.6023 - accuracy: 0.6593 - val_loss: 0.5927 - val_accuracy: 0.6681\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5988 - accuracy: 0.6629 - val_loss: 0.5915 - val_accuracy: 0.6709\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5972 - accuracy: 0.6628 - val_loss: 0.5882 - val_accuracy: 0.6687\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5961 - accuracy: 0.6641 - val_loss: 0.5844 - val_accuracy: 0.6716\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5961 - accuracy: 0.6649 - val_loss: 0.5856 - val_accuracy: 0.6687\n",
      "Epoch 9/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5953 - accuracy: 0.6664 - val_loss: 0.5888 - val_accuracy: 0.6711\n",
      "Epoch 10/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5934 - accuracy: 0.6652 - val_loss: 0.5880 - val_accuracy: 0.6656\n",
      "Epoch 11/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5952 - accuracy: 0.6665 - val_loss: 0.5848 - val_accuracy: 0.6725\n",
      "Epoch 12/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5914 - accuracy: 0.6672 - val_loss: 0.5881 - val_accuracy: 0.6708\n",
      "1111/1111 [==============================] - 1s 514us/step - loss: 0.5899 - accuracy: 0.6660\n",
      "Epoch 1/100\n",
      "1999/1999 [==============================] - 5s 2ms/step - loss: 0.6424 - accuracy: 0.6215 - val_loss: 0.6067 - val_accuracy: 0.6527\n",
      "Epoch 2/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.6101 - accuracy: 0.6489 - val_loss: 0.6045 - val_accuracy: 0.6569\n",
      "Epoch 3/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.6039 - accuracy: 0.6565 - val_loss: 0.6116 - val_accuracy: 0.6563\n",
      "Epoch 4/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.6012 - accuracy: 0.6596 - val_loss: 0.6003 - val_accuracy: 0.6606\n",
      "Epoch 5/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.6016 - accuracy: 0.6600 - val_loss: 0.5991 - val_accuracy: 0.6589\n",
      "Epoch 6/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5989 - accuracy: 0.6618 - val_loss: 0.5980 - val_accuracy: 0.6617\n",
      "Epoch 7/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5980 - accuracy: 0.6613 - val_loss: 0.5997 - val_accuracy: 0.6628\n",
      "Epoch 8/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5969 - accuracy: 0.6617 - val_loss: 0.6036 - val_accuracy: 0.6603\n",
      "Epoch 9/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5975 - accuracy: 0.6605 - val_loss: 0.5990 - val_accuracy: 0.6621\n",
      "Epoch 10/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5958 - accuracy: 0.6610 - val_loss: 0.5982 - val_accuracy: 0.6598\n",
      "Epoch 11/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5949 - accuracy: 0.6666 - val_loss: 0.5978 - val_accuracy: 0.6643\n",
      "Epoch 12/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5917 - accuracy: 0.6686 - val_loss: 0.6035 - val_accuracy: 0.6653\n",
      "Epoch 13/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5917 - accuracy: 0.6664 - val_loss: 0.5961 - val_accuracy: 0.6654\n",
      "Epoch 14/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5947 - accuracy: 0.6635 - val_loss: 0.5926 - val_accuracy: 0.6639\n",
      "Epoch 15/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5927 - accuracy: 0.6679 - val_loss: 0.5921 - val_accuracy: 0.6661\n",
      "Epoch 16/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5903 - accuracy: 0.6687 - val_loss: 0.5936 - val_accuracy: 0.6661\n",
      "Epoch 17/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5907 - accuracy: 0.6651 - val_loss: 0.5920 - val_accuracy: 0.6665\n",
      "Epoch 18/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5866 - accuracy: 0.6697 - val_loss: 0.5938 - val_accuracy: 0.6638\n",
      "Epoch 19/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5895 - accuracy: 0.6716 - val_loss: 0.5930 - val_accuracy: 0.6662\n",
      "Epoch 20/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5889 - accuracy: 0.6717 - val_loss: 0.5913 - val_accuracy: 0.6671\n",
      "Epoch 21/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5898 - accuracy: 0.6671 - val_loss: 0.5949 - val_accuracy: 0.6558\n",
      "Epoch 22/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5911 - accuracy: 0.6674 - val_loss: 0.5938 - val_accuracy: 0.6646\n",
      "Epoch 23/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5903 - accuracy: 0.6683 - val_loss: 0.5932 - val_accuracy: 0.6678\n",
      "Epoch 24/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5886 - accuracy: 0.6696 - val_loss: 0.5943 - val_accuracy: 0.6653\n",
      "Epoch 25/100\n",
      "1999/1999 [==============================] - 4s 2ms/step - loss: 0.5892 - accuracy: 0.6697 - val_loss: 0.5936 - val_accuracy: 0.6673\n",
      "1111/1111 [==============================] - 1s 510us/step - loss: 0.5881 - accuracy: 0.6668\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4684/4684 [==============================] - 7s 1ms/step - loss: 0.6303 - accuracy: 0.6323 - val_loss: 0.5990 - val_accuracy: 0.6633\n",
      "Epoch 2/100\n",
      "4684/4684 [==============================] - 6s 1ms/step - loss: 0.6079 - accuracy: 0.6547 - val_loss: 0.6002 - val_accuracy: 0.6568\n",
      "Epoch 3/100\n",
      "4684/4684 [==============================] - 6s 1ms/step - loss: 0.6027 - accuracy: 0.6578 - val_loss: 0.5920 - val_accuracy: 0.6694\n",
      "Epoch 4/100\n",
      "4684/4684 [==============================] - 6s 1ms/step - loss: 0.6011 - accuracy: 0.6593 - val_loss: 0.5956 - val_accuracy: 0.6653\n",
      "Epoch 5/100\n",
      "4684/4684 [==============================] - 6s 1ms/step - loss: 0.5976 - accuracy: 0.6633 - val_loss: 0.5881 - val_accuracy: 0.6709\n",
      "Epoch 6/100\n",
      "4684/4684 [==============================] - 6s 1ms/step - loss: 0.5964 - accuracy: 0.6631 - val_loss: 0.5887 - val_accuracy: 0.6723\n",
      "Epoch 7/100\n",
      "4684/4684 [==============================] - 6s 1ms/step - loss: 0.5951 - accuracy: 0.6620 - val_loss: 0.5898 - val_accuracy: 0.6738\n",
      "Epoch 8/100\n",
      "4684/4684 [==============================] - 6s 1ms/step - loss: 0.5938 - accuracy: 0.6664 - val_loss: 0.5861 - val_accuracy: 0.6694\n",
      "Epoch 9/100\n",
      "4684/4684 [==============================] - 6s 1ms/step - loss: 0.5931 - accuracy: 0.6652 - val_loss: 0.5888 - val_accuracy: 0.6720\n",
      "Epoch 10/100\n",
      "4684/4684 [==============================] - 6s 1ms/step - loss: 0.5916 - accuracy: 0.6683 - val_loss: 0.5875 - val_accuracy: 0.6658\n",
      "Epoch 11/100\n",
      "4684/4684 [==============================] - 6s 1ms/step - loss: 0.5936 - accuracy: 0.6658 - val_loss: 0.5853 - val_accuracy: 0.6732\n",
      "Epoch 12/100\n",
      "4684/4684 [==============================] - 6s 1ms/step - loss: 0.5924 - accuracy: 0.6663 - val_loss: 0.5873 - val_accuracy: 0.6716\n",
      "Epoch 13/100\n",
      "4684/4684 [==============================] - 6s 1ms/step - loss: 0.5917 - accuracy: 0.6661 - val_loss: 0.5847 - val_accuracy: 0.6743\n",
      "Epoch 14/100\n",
      "4684/4684 [==============================] - 6s 1ms/step - loss: 0.5921 - accuracy: 0.6665 - val_loss: 0.5888 - val_accuracy: 0.6726\n",
      "Epoch 15/100\n",
      "4684/4684 [==============================] - 6s 1ms/step - loss: 0.5917 - accuracy: 0.6653 - val_loss: 0.5871 - val_accuracy: 0.6734\n",
      "Epoch 16/100\n",
      "4684/4684 [==============================] - 6s 1ms/step - loss: 0.5897 - accuracy: 0.6682 - val_loss: 0.5892 - val_accuracy: 0.6681\n",
      "Epoch 17/100\n",
      "4684/4684 [==============================] - 6s 1ms/step - loss: 0.5887 - accuracy: 0.6694 - val_loss: 0.5902 - val_accuracy: 0.6728\n",
      "Epoch 18/100\n",
      "4684/4684 [==============================] - 6s 1ms/step - loss: 0.5912 - accuracy: 0.6667 - val_loss: 0.5852 - val_accuracy: 0.6725\n",
      "Search took: 69.03 mins\n"
     ]
    }
   ],
   "source": [
    "#Grid Search\n",
    "\n",
    "param_grid = {'n_hidden': [5, 10, 15], 'n_neurons': [25, 30], 'batch_size': [20, 32, 50]} \n",
    "\n",
    "checkpoint_grid = keras.callbacks.ModelCheckpoint('grid_model.h5', save_best_only=True)\n",
    "early_stopping_grid = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model1_grid = GridSearchCV(keras_classif, param_grid, cv=3)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "model1_g = model1_grid.fit(X_train_transformed, y_train, epochs=100, validation_split=0.1,\n",
    "          callbacks=[checkpoint_grid, early_stopping_grid] )\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"Search took: {:.2f} mins\".format((t1-t0)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d0aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_search_model = keras.models.load_model(\"grid_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c9d1189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32, 'n_hidden': 10, 'n_neurons': 30}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_g.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a9485a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.667315 with: {'batch_size': 20, 'n_hidden': 15, 'n_neurons': 30}\n",
      "0.667784 with: {'batch_size': 20, 'n_hidden': 5, 'n_neurons': 30}\n",
      "0.667814 with: {'batch_size': 50, 'n_hidden': 15, 'n_neurons': 30}\n",
      "0.668006 with: {'batch_size': 20, 'n_hidden': 10, 'n_neurons': 25}\n",
      "0.668030 with: {'batch_size': 50, 'n_hidden': 5, 'n_neurons': 25}\n",
      "0.668048 with: {'batch_size': 20, 'n_hidden': 10, 'n_neurons': 30}\n",
      "0.668192 with: {'batch_size': 50, 'n_hidden': 15, 'n_neurons': 25}\n",
      "0.668270 with: {'batch_size': 32, 'n_hidden': 15, 'n_neurons': 25}\n",
      "0.668324 with: {'batch_size': 20, 'n_hidden': 15, 'n_neurons': 25}\n",
      "0.668588 with: {'batch_size': 20, 'n_hidden': 5, 'n_neurons': 25}\n",
      "0.668703 with: {'batch_size': 50, 'n_hidden': 10, 'n_neurons': 25}\n",
      "0.668823 with: {'batch_size': 32, 'n_hidden': 5, 'n_neurons': 30}\n",
      "0.668871 with: {'batch_size': 32, 'n_hidden': 5, 'n_neurons': 25}\n",
      "0.669093 with: {'batch_size': 50, 'n_hidden': 5, 'n_neurons': 30}\n",
      "0.669129 with: {'batch_size': 32, 'n_hidden': 10, 'n_neurons': 25}\n",
      "0.669195 with: {'batch_size': 50, 'n_hidden': 10, 'n_neurons': 30}\n",
      "0.669225 with: {'batch_size': 32, 'n_hidden': 15, 'n_neurons': 30}\n",
      "0.669291 with: {'batch_size': 32, 'n_hidden': 10, 'n_neurons': 30}\n"
     ]
    }
   ],
   "source": [
    "for mean, params in sorted(zip(model1_g.cv_results_['mean_test_score'], model1_g.cv_results_['params'])):\n",
    "    print(\"%f with: %r\" %(mean, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612b560f",
   "metadata": {},
   "source": [
    "best: batch size=32, layers=10, nodes=30, acc=66.929\n",
    "2nd best: batch size=32 layers=15, nodes=30, acc=66.922\n",
    "3rd best: batch_size=32, layers=10, nodes=30, acc=66.919\n",
    "\n",
    "Use Kera Tuner to tune with batch_size between 32 and 50,\n",
    "layers between 10 to 25\n",
    "number of neurons between 25 to 40\n",
    "activation selu with lecun initilization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fdc929c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid = keras.models.load_model(\"grid_model.h5\") #model1_g.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5d2cb1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2231/2231 [==============================] - 1s 274us/step - loss: 0.5895 - accuracy: 0.6675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5895346403121948, 0.667493462562561]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_grid.evaluate(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca0806",
   "metadata": {},
   "source": [
    "### Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "929e2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.tuners import RandomSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "13e71a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_tuner(hp):\n",
    "    model_kt = keras.models.Sequential()\n",
    "    model_kt.add(keras.layers.InputLayer(input_shape=X_train_transformed.shape[1:]))\n",
    "    for layer in range(hp.Int('n_layers',10, 20, step=1)):\n",
    "        model_kt.add(keras.layers.Dense(units=hp.Int('units', min_value=30, max_value=50, step=2),\n",
    "                    kernel_initializer='lecun_normal'))\n",
    "        model_kt.add(keras.layers.BatchNormalization())\n",
    "        model_kt.add(keras.layers.Activation(activation='selu'))\n",
    "    model_kt.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    lr = hp.Float(\"lr\", min_value=1e-3 , max_value=0.1)\n",
    "    model_kt.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=lr), \n",
    "                                                                                 metrics=['accuracy'])\n",
    "    \n",
    "    return model_kt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c97bfa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(build_model_tuner,\n",
    "                    objective = 'val_accuracy',\n",
    "                    max_trials = 25,\n",
    "                    executions_per_trial=1,\n",
    "                    directory='NationalCollisionLogs',\n",
    "                    project_name='Tuner1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6e9ab7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "n_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 30, 'max_value': 50, 'step': 2, 'sampling': None}\n",
      "lr (Float)\n",
      "{'default': 0.001, 'conditions': [], 'min_value': 0.001, 'max_value': 0.1, 'step': None, 'sampling': None}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3cc195dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 Complete [00h 01m 21s]\n",
      "val_accuracy: 0.6728124618530273\n",
      "\n",
      "Best val_accuracy So Far: 0.6760554909706116\n",
      "Total elapsed time: 00h 44m 15s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Search took: 44.24 mins\n"
     ]
    }
   ],
   "source": [
    "#checkpoint_tuner = keras.callbacks.ModelCheckpoint('tuner_model.h5', save_best_only=True)\n",
    "\n",
    "#early_stopping_grid = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "t0 = time.time()\n",
    "tuner.search(X_train_transformed, y_train, epochs=100, validation_split=0.1,\n",
    "            callbacks=[keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)])\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"Search took: {:.2f} mins\".format((t1-t0)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "864938ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in NationalCollisionLogs/Tuner1\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7fe37b74acd0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 20\n",
      "units: 36\n",
      "lr: 0.0020354191041813225\n",
      "Score: 0.6760554909706116\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 14\n",
      "units: 34\n",
      "lr: 0.023602130543966933\n",
      "Score: 0.6746742129325867\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 17\n",
      "units: 46\n",
      "lr: 0.012460713342286982\n",
      "Score: 0.6737132668495178\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 18\n",
      "units: 32\n",
      "lr: 0.06331652671566725\n",
      "Score: 0.6733529567718506\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 13\n",
      "units: 34\n",
      "lr: 0.06858887662678276\n",
      "Score: 0.6733529567718506\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 19\n",
      "units: 44\n",
      "lr: 0.02224472975661917\n",
      "Score: 0.6728724837303162\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 19\n",
      "units: 34\n",
      "lr: 0.027989401818685665\n",
      "Score: 0.6728124618530273\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 12\n",
      "units: 30\n",
      "lr: 0.050812678446296125\n",
      "Score: 0.6728124618530273\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 13\n",
      "units: 48\n",
      "lr: 0.04532173576000593\n",
      "Score: 0.6725121736526489\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 15\n",
      "units: 36\n",
      "lr: 0.021913641066724183\n",
      "Score: 0.6718515157699585\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f844da01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_layers': 20, 'units': 36, 'lr': 0.0020354191041813225}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 36)                1548      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 36)                144       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 37        \n",
      "=================================================================\n",
      "Total params: 29,773\n",
      "Trainable params: 28,333\n",
      "Non-trainable params: 1,440\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#best hyperparameteer/model values\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.get_best_models()[0].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1fbc1965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_layers': 20, 'units': 36, 'lr': 0.0020354191041813225}\n"
     ]
    }
   ],
   "source": [
    "print(tuner.get_best_hyperparameters(2)[0].values)\n",
    "#best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a9ba6ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5204/5204 [==============================] - 12s 2ms/step - loss: 0.6346 - accuracy: 0.6307\n",
      "Epoch 2/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.6097 - accuracy: 0.6517\n",
      "Epoch 3/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.6054 - accuracy: 0.6549\n",
      "Epoch 4/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.6038 - accuracy: 0.6553\n",
      "Epoch 5/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.6028 - accuracy: 0.6584\n",
      "Epoch 6/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5987 - accuracy: 0.6626\n",
      "Epoch 7/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.6004 - accuracy: 0.6615\n",
      "Epoch 8/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5984 - accuracy: 0.6613\n",
      "Epoch 9/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5960 - accuracy: 0.6640\n",
      "Epoch 10/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5965 - accuracy: 0.6643\n",
      "Epoch 11/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5963 - accuracy: 0.6633\n",
      "Epoch 12/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5927 - accuracy: 0.6687\n",
      "Epoch 13/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5939 - accuracy: 0.6675\n",
      "Epoch 14/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5942 - accuracy: 0.6663\n",
      "Epoch 15/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5924 - accuracy: 0.6668\n",
      "Epoch 16/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5929 - accuracy: 0.6666\n",
      "Epoch 17/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5925 - accuracy: 0.6673\n",
      "Epoch 18/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5924 - accuracy: 0.6682\n",
      "Epoch 19/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5898 - accuracy: 0.6712\n",
      "Epoch 20/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5916 - accuracy: 0.6681\n",
      "Epoch 21/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5904 - accuracy: 0.6712\n",
      "Epoch 22/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5920 - accuracy: 0.6680\n",
      "Epoch 23/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5901 - accuracy: 0.6700\n",
      "Epoch 24/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5911 - accuracy: 0.6693\n",
      "Epoch 25/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5911 - accuracy: 0.6687\n",
      "Epoch 26/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5891 - accuracy: 0.6691\n",
      "Epoch 27/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5894 - accuracy: 0.6698\n",
      "Epoch 28/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5886 - accuracy: 0.6713\n",
      "Epoch 29/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5913 - accuracy: 0.6684\n",
      "Epoch 30/30\n",
      "5204/5204 [==============================] - 11s 2ms/step - loss: 0.5891 - accuracy: 0.6706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe39e3acee0>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the best hyperparameters and train the model on the full training set\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(2)\n",
    "best_model = build_model_tuner(best_hps[0])\n",
    "\n",
    "best_model.fit(X_train_transformed, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7913bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the best neural network model\n",
    "\n",
    "best_model.save(\"nn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2df4bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = keras.models.load_model('nn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6059b5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2231/2231 [==============================] - 1s 526us/step - loss: 0.5907 - accuracy: 0.6674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.590666651725769, 0.6673673391342163]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate on the test set\n",
    "\n",
    "nn_model.evaluate(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a118489e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec8dcf5b",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduling\n",
    "### Performance scheduling using ReduceLROnPlateau callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5285b888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4684/4684 [==============================] - 12s 2ms/step - loss: 0.6452 - accuracy: 0.6188 - val_loss: 0.6021 - val_accuracy: 0.6607\n",
      "Epoch 2/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.6246 - accuracy: 0.6402 - val_loss: 0.7475 - val_accuracy: 0.6152\n",
      "Epoch 3/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.6225 - accuracy: 0.6445 - val_loss: 0.6222 - val_accuracy: 0.6135\n",
      "Epoch 4/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.6175 - accuracy: 0.6454 - val_loss: 0.6979 - val_accuracy: 0.5834\n",
      "Epoch 5/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.6248 - accuracy: 0.6447 - val_loss: 0.6456 - val_accuracy: 0.5789\n",
      "Epoch 6/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.6201 - accuracy: 0.6468 - val_loss: 0.6480 - val_accuracy: 0.6018\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.020000000298023225.\n",
      "Epoch 7/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5996 - accuracy: 0.6620 - val_loss: 0.5917 - val_accuracy: 0.6723\n",
      "Epoch 8/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5971 - accuracy: 0.6631 - val_loss: 0.5912 - val_accuracy: 0.6674\n",
      "Epoch 9/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5976 - accuracy: 0.6641 - val_loss: 0.5914 - val_accuracy: 0.6750\n",
      "Epoch 10/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5984 - accuracy: 0.6637 - val_loss: 0.5951 - val_accuracy: 0.6624\n",
      "Epoch 11/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5966 - accuracy: 0.6637 - val_loss: 0.6088 - val_accuracy: 0.6356\n",
      "Epoch 12/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5971 - accuracy: 0.6647 - val_loss: 0.5969 - val_accuracy: 0.6522\n",
      "Epoch 13/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5929 - accuracy: 0.6661 - val_loss: 0.5887 - val_accuracy: 0.6713\n",
      "Epoch 14/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5952 - accuracy: 0.6668 - val_loss: 0.5944 - val_accuracy: 0.6585\n",
      "Epoch 15/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5942 - accuracy: 0.6654 - val_loss: 0.5885 - val_accuracy: 0.6722\n",
      "Epoch 16/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5954 - accuracy: 0.6657 - val_loss: 0.5869 - val_accuracy: 0.6728\n",
      "Epoch 17/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5949 - accuracy: 0.6637 - val_loss: 0.5961 - val_accuracy: 0.6519\n",
      "Epoch 18/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5971 - accuracy: 0.6635 - val_loss: 0.5991 - val_accuracy: 0.6702\n",
      "Epoch 19/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5952 - accuracy: 0.6659 - val_loss: 0.5928 - val_accuracy: 0.6714\n",
      "Epoch 20/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5942 - accuracy: 0.6662 - val_loss: 0.5897 - val_accuracy: 0.6726\n",
      "Epoch 21/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5975 - accuracy: 0.6624 - val_loss: 0.5934 - val_accuracy: 0.6707\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.003999999910593033.\n",
      "Epoch 22/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5902 - accuracy: 0.6687 - val_loss: 0.5938 - val_accuracy: 0.6673\n",
      "Epoch 23/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5904 - accuracy: 0.6693 - val_loss: 0.5907 - val_accuracy: 0.6726\n",
      "Epoch 24/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5910 - accuracy: 0.6699 - val_loss: 0.5876 - val_accuracy: 0.6732\n",
      "Epoch 25/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5912 - accuracy: 0.6687 - val_loss: 0.5873 - val_accuracy: 0.6728\n",
      "Epoch 26/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5879 - accuracy: 0.6715 - val_loss: 0.5876 - val_accuracy: 0.6742\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0007999999448657036.\n",
      "Epoch 27/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5907 - accuracy: 0.6689 - val_loss: 0.5891 - val_accuracy: 0.6727\n",
      "Epoch 28/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5901 - accuracy: 0.6699 - val_loss: 0.5922 - val_accuracy: 0.6705\n",
      "Epoch 29/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5913 - accuracy: 0.6676 - val_loss: 0.5887 - val_accuracy: 0.6711\n",
      "Epoch 30/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5893 - accuracy: 0.6700 - val_loss: 0.5883 - val_accuracy: 0.6723\n",
      "Epoch 31/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5902 - accuracy: 0.6705 - val_loss: 0.5872 - val_accuracy: 0.6744\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00015999998431652786.\n",
      "Epoch 32/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5908 - accuracy: 0.6672 - val_loss: 0.5869 - val_accuracy: 0.6745\n",
      "Epoch 33/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5905 - accuracy: 0.6690 - val_loss: 0.5889 - val_accuracy: 0.6725\n",
      "Epoch 34/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5907 - accuracy: 0.6680 - val_loss: 0.5871 - val_accuracy: 0.6745\n",
      "Epoch 35/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5890 - accuracy: 0.6707 - val_loss: 0.5881 - val_accuracy: 0.6731\n",
      "Epoch 36/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5899 - accuracy: 0.6701 - val_loss: 0.5872 - val_accuracy: 0.6741\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-05.\n",
      "Epoch 37/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5900 - accuracy: 0.6698 - val_loss: 0.5853 - val_accuracy: 0.6746\n",
      "Epoch 38/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5911 - accuracy: 0.6685 - val_loss: 0.5873 - val_accuracy: 0.6744\n",
      "Epoch 39/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5895 - accuracy: 0.6691 - val_loss: 0.5872 - val_accuracy: 0.6750\n",
      "Epoch 40/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5889 - accuracy: 0.6712 - val_loss: 0.5878 - val_accuracy: 0.6747\n",
      "Epoch 41/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5888 - accuracy: 0.6702 - val_loss: 0.5882 - val_accuracy: 0.6726\n",
      "Epoch 42/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5890 - accuracy: 0.6696 - val_loss: 0.5922 - val_accuracy: 0.6705\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 6.399999256245792e-06.\n",
      "Epoch 43/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5907 - accuracy: 0.6678 - val_loss: 0.5865 - val_accuracy: 0.6743\n",
      "Epoch 44/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5910 - accuracy: 0.6681 - val_loss: 0.5896 - val_accuracy: 0.6723\n",
      "Epoch 45/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5893 - accuracy: 0.6691 - val_loss: 0.5886 - val_accuracy: 0.6728\n",
      "Epoch 46/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5891 - accuracy: 0.6698 - val_loss: 0.5896 - val_accuracy: 0.6728\n",
      "Epoch 47/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5914 - accuracy: 0.6689 - val_loss: 0.5885 - val_accuracy: 0.6731\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.2799998330592645e-06.\n",
      "Epoch 48/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5896 - accuracy: 0.6686 - val_loss: 0.5859 - val_accuracy: 0.6750\n",
      "Epoch 49/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5889 - accuracy: 0.6691 - val_loss: 0.5887 - val_accuracy: 0.6732\n",
      "Epoch 50/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5898 - accuracy: 0.6700 - val_loss: 0.5918 - val_accuracy: 0.6708\n",
      "Epoch 51/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5886 - accuracy: 0.6699 - val_loss: 0.5869 - val_accuracy: 0.6743\n",
      "Epoch 52/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5891 - accuracy: 0.6697 - val_loss: 0.5876 - val_accuracy: 0.6745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 2.559999757067999e-07.\n",
      "Epoch 53/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5923 - accuracy: 0.6670 - val_loss: 0.5867 - val_accuracy: 0.6746\n",
      "Epoch 54/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5871 - accuracy: 0.6705 - val_loss: 0.5852 - val_accuracy: 0.6750\n",
      "Epoch 55/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5908 - accuracy: 0.6692 - val_loss: 0.5874 - val_accuracy: 0.6749\n",
      "Epoch 56/100\n",
      "4684/4684 [==============================] - 9s 2ms/step - loss: 0.5890 - accuracy: 0.6689 - val_loss: 0.5841 - val_accuracy: 0.6750\n",
      "Epoch 57/100\n",
      "4684/4684 [==============================] - 9s 2ms/step - loss: 0.5893 - accuracy: 0.6702 - val_loss: 0.5899 - val_accuracy: 0.6725\n",
      "Epoch 58/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5907 - accuracy: 0.6701 - val_loss: 0.5870 - val_accuracy: 0.6747\n",
      "Epoch 59/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5902 - accuracy: 0.6687 - val_loss: 0.5900 - val_accuracy: 0.6725\n",
      "Epoch 60/100\n",
      "4684/4684 [==============================] - 9s 2ms/step - loss: 0.5899 - accuracy: 0.6704 - val_loss: 0.5884 - val_accuracy: 0.6732\n",
      "Epoch 61/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5901 - accuracy: 0.6689 - val_loss: 0.5851 - val_accuracy: 0.6749\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 5.1199992867623226e-08.\n",
      "Epoch 62/100\n",
      "4684/4684 [==============================] - 9s 2ms/step - loss: 0.5877 - accuracy: 0.6716 - val_loss: 0.5888 - val_accuracy: 0.6724\n",
      "Epoch 63/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5885 - accuracy: 0.6720 - val_loss: 0.5911 - val_accuracy: 0.6720\n",
      "Epoch 64/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5888 - accuracy: 0.6690 - val_loss: 0.5868 - val_accuracy: 0.6744\n",
      "Epoch 65/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5893 - accuracy: 0.6715 - val_loss: 0.5885 - val_accuracy: 0.6737\n",
      "Epoch 66/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5910 - accuracy: 0.6674 - val_loss: 0.5876 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.0239998715633193e-08.\n",
      "Epoch 67/100\n",
      "4684/4684 [==============================] - 9s 2ms/step - loss: 0.5908 - accuracy: 0.6676 - val_loss: 0.5861 - val_accuracy: 0.6750\n",
      "Epoch 68/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5902 - accuracy: 0.6687 - val_loss: 0.5897 - val_accuracy: 0.6717\n",
      "Epoch 69/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5892 - accuracy: 0.6697 - val_loss: 0.5902 - val_accuracy: 0.6716\n",
      "Epoch 70/100\n",
      "4684/4684 [==============================] - 9s 2ms/step - loss: 0.5900 - accuracy: 0.6686 - val_loss: 0.5906 - val_accuracy: 0.6708\n",
      "Epoch 71/100\n",
      "4684/4684 [==============================] - 9s 2ms/step - loss: 0.5879 - accuracy: 0.6703 - val_loss: 0.5873 - val_accuracy: 0.6744\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 2.047999814180912e-09.\n",
      "Epoch 72/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5882 - accuracy: 0.6719 - val_loss: 0.5867 - val_accuracy: 0.6744\n",
      "Epoch 73/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5904 - accuracy: 0.6691 - val_loss: 0.5904 - val_accuracy: 0.6716\n",
      "Epoch 74/100\n",
      "4684/4684 [==============================] - 9s 2ms/step - loss: 0.5913 - accuracy: 0.6695 - val_loss: 0.5882 - val_accuracy: 0.6738\n",
      "Epoch 75/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5911 - accuracy: 0.6687 - val_loss: 0.5892 - val_accuracy: 0.6725\n",
      "Epoch 76/100\n",
      "4684/4684 [==============================] - 9s 2ms/step - loss: 0.5889 - accuracy: 0.6701 - val_loss: 0.5855 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 4.0959995395439823e-10.\n",
      "Epoch 77/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5919 - accuracy: 0.6684 - val_loss: 0.5881 - val_accuracy: 0.6735\n",
      "Epoch 78/100\n",
      "4684/4684 [==============================] - 9s 2ms/step - loss: 0.5921 - accuracy: 0.6665 - val_loss: 0.5882 - val_accuracy: 0.6731\n",
      "Epoch 79/100\n",
      "4684/4684 [==============================] - 9s 2ms/step - loss: 0.5903 - accuracy: 0.6697 - val_loss: 0.5892 - val_accuracy: 0.6726\n",
      "Epoch 80/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5902 - accuracy: 0.6683 - val_loss: 0.5901 - val_accuracy: 0.6720\n",
      "Epoch 81/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5897 - accuracy: 0.6705 - val_loss: 0.5888 - val_accuracy: 0.6730\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 8.19199930113257e-11.\n",
      "Epoch 82/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5909 - accuracy: 0.6691 - val_loss: 0.5901 - val_accuracy: 0.6719\n",
      "Epoch 83/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5919 - accuracy: 0.6668 - val_loss: 0.5867 - val_accuracy: 0.6752\n",
      "Epoch 84/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5909 - accuracy: 0.6699 - val_loss: 0.5854 - val_accuracy: 0.6745\n",
      "Epoch 85/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5902 - accuracy: 0.6688 - val_loss: 0.5897 - val_accuracy: 0.6722\n",
      "Epoch 86/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5896 - accuracy: 0.6709 - val_loss: 0.5896 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 1.638399832470938e-11.\n",
      "Epoch 87/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5918 - accuracy: 0.6682 - val_loss: 0.5860 - val_accuracy: 0.6747\n",
      "Epoch 88/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5887 - accuracy: 0.6700 - val_loss: 0.5911 - val_accuracy: 0.6701\n",
      "Epoch 89/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5906 - accuracy: 0.6691 - val_loss: 0.5887 - val_accuracy: 0.6734\n",
      "Epoch 90/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5899 - accuracy: 0.6678 - val_loss: 0.5860 - val_accuracy: 0.6749\n",
      "Epoch 91/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5892 - accuracy: 0.6680 - val_loss: 0.5869 - val_accuracy: 0.6744\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 3.2767996649418765e-12.\n",
      "Epoch 92/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5905 - accuracy: 0.6678 - val_loss: 0.5893 - val_accuracy: 0.6722\n",
      "Epoch 93/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5897 - accuracy: 0.6695 - val_loss: 0.5897 - val_accuracy: 0.6724\n",
      "Epoch 94/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5900 - accuracy: 0.6661 - val_loss: 0.5900 - val_accuracy: 0.6721\n",
      "Epoch 95/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5900 - accuracy: 0.6686 - val_loss: 0.5863 - val_accuracy: 0.6743\n",
      "Epoch 96/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5896 - accuracy: 0.6686 - val_loss: 0.5861 - val_accuracy: 0.6751\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 6.553599243147579e-13.\n",
      "Epoch 97/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5890 - accuracy: 0.6685 - val_loss: 0.5890 - val_accuracy: 0.6728\n",
      "Epoch 98/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5889 - accuracy: 0.6706 - val_loss: 0.5905 - val_accuracy: 0.6715\n",
      "Epoch 99/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5892 - accuracy: 0.6705 - val_loss: 0.5882 - val_accuracy: 0.6738\n",
      "Epoch 100/100\n",
      "4684/4684 [==============================] - 10s 2ms/step - loss: 0.5897 - accuracy: 0.6692 - val_loss: 0.5861 - val_accuracy: 0.6741\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.models.Sequential()\n",
    "model2.add(keras.layers.InputLayer(input_shape=X_train_transformed.shape[1:]))\n",
    "for i in range(20):\n",
    "    model2.add(keras.layers.Dense(36, kernel_initializer='lecun_normal'))\n",
    "    model2.add(keras.layers.BatchNormalization())\n",
    "    model2.add(keras.layers.Activation(activation='selu'))\n",
    "    \n",
    "model2.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callback_lr = keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=5, verbose=2)\n",
    "\n",
    "hist_reduce_lr = model2.fit(X_train_transformed, y_train, epochs=100, validation_split=0.1,\n",
    "          callbacks=[callback_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b4c67d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2231/2231 [==============================] - 1s 536us/step - loss: 0.5904 - accuracy: 0.6663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5904138684272766, 0.6663163304328918]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40cc6a7",
   "metadata": {},
   "source": [
    "Draw roc_auc_curve for the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65299f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7340212576720065, 0.7273667387023048)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#roc score for train and test data\n",
    "\n",
    "y_train_kpred = nn_model.predict(X_train_transformed).ravel()\n",
    "fpr_train_nn, tpr_train_nn, ths_train_nn = roc_curve(y_train, y_train_kpred)\n",
    "keras_train_roc_auc = roc_auc_score(y_train, y_train_kpred)\n",
    "\n",
    "\n",
    "y_test_kpred = nn_model.predict(X_test_transformed).ravel()\n",
    "fpr_test_nn, tpr_test_nn, ths_test_nn = roc_curve(y_test, y_test_kpred)\n",
    "keras_test_roc_auc = roc_auc_score(y_test, y_test_kpred)\n",
    "\n",
    "keras_train_roc_auc, keras_test_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6b78211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the variables required for ROC curves\n",
    "\n",
    "np.save('fpr_train_nn.npy', fpr_train_nn)\n",
    "np.save('tpr_train_nn.npy', tpr_train_nn)\n",
    "np.save('fpr_test_nn.npy', fpr_test_nn)\n",
    "np.save('tpr_test_nn.npy', tpr_test_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857bef75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
